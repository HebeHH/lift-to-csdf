{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "liftdir = \"/Users/hebe/Dropbox/Yale-NUS/Yr4/capstone/forrealsies/lift\"\n",
    "\n",
    "import os, re\n",
    "import pandas as pd\n",
    "# from typing import NamedTuple\n",
    "\n",
    "def flatten(lol):\n",
    "    return [val for sublist in lol for val in sublist]\n",
    "\n",
    "# class Node(NamedTuple):\n",
    "#     name: str\n",
    "#     kind: str\n",
    "        \n",
    "# class Edge(NamedTuple):\n",
    "#     source: str\n",
    "#     target: str\n",
    "#     code: str\n",
    "        \n",
    "class Edge():\n",
    "    def __init__(self, source :str, target :str, code :str):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        self.code = code\n",
    "        pass\n",
    "class EdgeList():\n",
    "    def __init__(self, incoming: list, outgoing: list):\n",
    "        self.incoming = incoming\n",
    "        self.outgoing = outgoing\n",
    "        pass\n",
    "class Graph():\n",
    "    def __init__(self, name: str, nodes : dict, edges : dict, info : dict ):\n",
    "        self.name = name\n",
    "        self.nodes = nodes\n",
    "        self.edges = edges\n",
    "        self.info = info\n",
    "        pass\n",
    "# class EdgeList(NamedTuple):\n",
    "#     incoming: list\n",
    "#     outgoing: list\n",
    "\n",
    "# class Graph(NamedTuple):\n",
    "#     nodes: dict\n",
    "#     edges: dict\n",
    "        \n",
    "def not_connected(el):\n",
    "    return len(el.incoming) == 0 and len(el.outgoing) == 0\n",
    "\n",
    "def edge_match(e1, e2):\n",
    "    return e1.target == e2.target and e1.source == e2.source and e1.code == e2.code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poli0)0i'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"poli()0i\".replace(\"(\",\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_format(file):\n",
    "\n",
    "    # Read nodes and edges from program\n",
    "    with open(file) as f:\n",
    "        tmp = f.read()\n",
    "    tmp = tmp.split('\\n\\n\\n')\n",
    "    nodes_raw = tmp[0].split('\\n')[1:]\n",
    "    edges_raw = tmp[1].split('\\n')[1:-1]\n",
    "\n",
    "    # Dictionary of extracted node name -> type mapping\n",
    "    nodes = {}\n",
    "    info = {}\n",
    "    for node in nodes_raw:\n",
    "        tmp = node.split(':')\n",
    "        nodes[tmp[0].strip()] = re.sub(r'Lambda[0-9]+', 'Lambda', tmp[1]).strip()\n",
    "        info[tmp[0].strip()] = ':'.join(tmp[2:])\n",
    "\n",
    "    # Extract edge information\n",
    "    edge_split = [(x.split(' -> ')[0].strip(), \n",
    "               x.split(' -> ')[1].split(':')[0].strip(), \n",
    "               re.sub(r' \\(\\)','',x.split(':')[1]).strip()) \n",
    "              for x in edges_raw]\n",
    "\n",
    "    # Formatting edge information\n",
    "    edges = {}\n",
    "    for node in nodes.keys():\n",
    "        inc = [Edge(e[0], e[1], e[2]) for e in edge_split if e[1] == node] \n",
    "        out = [Edge(e[0], e[1], e[2]) for e in edge_split if e[0] == node]\n",
    "        edges[node] = EdgeList(inc, out)\n",
    "\n",
    "    # Find and remove lone nodes\n",
    "    # lone_nodes = [nodes.pop(n) for n in nodes.keys() if not_connected(edges[n])]\n",
    "    lone_nodes = [n for n in nodes.keys() if not_connected(edges[n])]\n",
    "    for lone_node in lone_nodes:\n",
    "        nodes.pop(lone_node)\n",
    "        info.pop(lone_node)\n",
    "\n",
    "    # Deal with funcalls with duplicated hashcode\n",
    "    # Current def of 'duplicated hashcode' is 'has multiple other nodes pointing to is as function'\n",
    "    dupl_funcall = [n for n, v in nodes.items() \n",
    "                     if v == 'FunCall' and len(edges[n].incoming) > 1]\n",
    "    \n",
    "    # TODO: must remove ALL edges on both sides and also add mirrored edges\n",
    "    def handle_weird_funcall(n):\n",
    "        # find n n\n",
    "        parents = [(e.source, e.code) for e in edges[n].incoming]\n",
    "        count = len(parents)\n",
    "        # separate and assert n copies of every kind of outgoing edge\n",
    "        child_codes = set([e.code for e in edges[n].outgoing])\n",
    "        child_edges = {}\n",
    "        for c in child_codes:\n",
    "            child_edges[c] = [e for e in edges[n].outgoing if e.code == c]\n",
    "            assert(count == len(child_edges[c]))\n",
    "        # create n duplicate nodes\n",
    "        # assign each a parent and a set of outgoing edges\n",
    "        for i in range(count):\n",
    "            new_name = 'n' + str(len(nodes.keys()) + 2)\n",
    "            nodes[new_name] = 'FunCall'\n",
    "            inc = [Edge(parents[i][0], new_name, parents[i][1])]\n",
    "            out = [Edge(new_name, child_edges[c][i], c) for c in child_codes]\n",
    "            edges[new_name] = EdgeList(inc, out)\n",
    "        # remove original node and all edges\n",
    "        nodes.pop(n)\n",
    "        edges.pop(n)\n",
    "        info.pop(n)\n",
    "\n",
    "    for df in dupl_funcall:\n",
    "        handle_weird_funcall(df)\n",
    "    \n",
    "    name = file.split('/')[-1]\n",
    "    return Graph(name, nodes, edges, info)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcall_f_targets = []\n",
    "\n",
    "def assumptions_checker(graph):  \n",
    "    nodes = graph.nodes\n",
    "    edges = graph.edges\n",
    "    \n",
    "    # FunCall Assertions:\n",
    "    funcalls = [n for n, v in nodes.items() if v == 'FunCall']\n",
    "    for funcall in funcalls:\n",
    "        # Each FunCall has excactly 1 incoming edge, \n",
    "        #      from either another FunCall or a Lambda, \n",
    "        #      as 'body' or 'arg_n'\n",
    "        inc = edges[funcall].incoming\n",
    "        assert len(inc) == 1, 'FunCall  has incorrect number of incoming edges' \n",
    "        assert inc[0].code != 'f', 'FunCall incedge is not \"f\"' \n",
    "        assert nodes[inc[0].source] in ['FunCall', 'Lambda'], 'FunCall incoming source is not a FunCall or Lambda'\n",
    "        \n",
    "        # Each FunCall has exactly one (outgoing edge labelled f)\n",
    "        # All other edges are 'arg_n' from 0 to num edges - 2\n",
    "        out = edges[funcall].outgoing\n",
    "        assert len([e for e in out if e.code == 'f']) == 1 \n",
    "        if len(out) > 1:\n",
    "            codes = [int(x) for x in re.findall(r'arg_([0-9]+)', ' '.join([e.code for e in out]))]\n",
    "            assert len(codes) == len(set(codes)), 'FunCall has duplicate arg codes' \n",
    "            assert min(codes) == 0, 'Funcall args do not start at 0' \n",
    "            assert max(codes) == len(out) - 2, 'FunCall args not incrementing correctly' \n",
    "#         print([nodes[e.target] for e in out if e.code == 'f'])\n",
    "\n",
    "    \n",
    "    # Lambda Assumptions\n",
    "    lambdas = [n for n, v in nodes.items() if v == 'Lambda']\n",
    "    for lam in lambdas:\n",
    "        # Each Lambda has 0 or 1 incoming edges, from Map, Reduce or ReduceSeq, as 'f'\n",
    "        inc = edges[lam].incoming\n",
    "        assert len(inc) <= 1, 'Lambda has too many incoming edges' \n",
    "        if len(inc) > 0:\n",
    "            assert nodes[inc[0].source] in ['Map', 'Reduce'],  'Lambda has incoming edge from odd source' \n",
    "            assert inc[0].code == 'f',  'Lambda has non-f incoming source' \n",
    "        \n",
    "        # Each lambda has exactly 1 (outgoing edge labelled body) which points to a FunCall\n",
    "        # All other outgoing edges are labelled 'param_n', n increasing from 0\n",
    "        out = edges[lam].outgoing\n",
    "        assert len([e for e in out if e.code == 'body']) == 1,  'Lambda does not have exactly one body' \n",
    "        assert len([e for e in out if e.code == 'body' and nodes[e.target] == 'FunCall']) == 1, 'Lambdas body is not a FunCall' \n",
    "        if len(out) > 1:\n",
    "            codes = [int(x) for x in re.findall(r'param_([0-9]+)', ' '.join([e.code for e in out]))]\n",
    "            assert len(codes) == len(set(codes)), 'Lambda has duplicate Param codes'\n",
    "            assert min(codes) == 0, 'Lambda Params do not start at 0' \n",
    "            assert max(codes) == len(out) - 2, 'Lambda Params do not increment properly' \n",
    "    \n",
    "    # Non-duplicate arg/param num assumptions:\n",
    "    for n in nodes.keys():\n",
    "        out = edges[n].outgoing\n",
    "        if len(out) > 1:\n",
    "            codes = [int(x) for x in re.findall(r'_([0-9]+)', ' '.join([e.code for e in out]))]\n",
    "            assert len(codes) == len(set(codes)), 'Node has duplicate parameter values'\n",
    "            assert min(codes) == 0, 'Node parameter nums do not start at 0' \n",
    "            assert max(codes) < len(out), 'Node parameters do not increment properly' \n",
    "    \n",
    "    # All nodes are connected\n",
    "    lone_nodes = [n for n in nodes.keys() if not_connected(edges[n])]\n",
    "    assert len(lone_nodes) == 0, \"Disconnected node in graph\"\n",
    "    \n",
    "    # Params don't point anywhere\n",
    "    for param in [n for n, v in nodes.items() if v == 'Param']:\n",
    "        assert len(edges[param].outgoing) == 0, \"Params don't point anywhere\"\n",
    "    \n",
    "    # All edges reference real nodes\n",
    "    for k, v in edges.items():\n",
    "        for e in v.incoming:\n",
    "            assert e.source in nodes and e.target in nodes, \"rootless edge\"\n",
    "            assert any([edge_match(x,e) for x in edges[e.source].outgoing]), \"non-mirrored edge\"\n",
    "        for e in v.outgoing:\n",
    "            assert e.source in nodes and e.target in nodes, \"rootless edge\"\n",
    "            assert any([edge_match(x,e) for x in edges[e.target].incoming]), \"non-mirrored edge\"\n",
    "#             assert e in edges[e.target].incoming, \"non-mirrored edge\"\n",
    "            \n",
    "    \n",
    "    return True\n",
    "\n",
    "def assert_assumptions(graph):\n",
    "    try:\n",
    "        return assumptions_checker(graph)\n",
    "    except AssertionError as e:\n",
    "        return str(e)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_wrappers(graph):\n",
    "    nodes = graph.nodes\n",
    "    edges = graph.edges\n",
    "    \n",
    "    # FunCalls:\n",
    "    for funcall in [n for n, v in nodes.items() if v == 'FunCall']:\n",
    "        f_node = [e.target for e in edges[funcall].outgoing if e.code == 'f'][0]\n",
    "        new_edges = [Edge(f_node, e.target, e.code) for e in edges[funcall].outgoing if e.code != 'f']\n",
    "        parent = edges[funcall].incoming[0].source\n",
    "        parent_edge = Edge(parent, f_node, edges[funcall].incoming[0].code)\n",
    "        # Attach all args to f node\n",
    "        edges[f_node].outgoing = edges[f_node].outgoing + new_edges\n",
    "        # Attach f node to args\n",
    "        for e in new_edges:\n",
    "            edges[e.target].incoming = edges[e.target].incoming + [e]\n",
    "        # Attach f node to parent\n",
    "        edges[parent].outgoing = edges[parent].outgoing +[parent_edge]\n",
    "        # Attach parent to f node:\n",
    "        edges[f_node].incoming = edges[f_node].incoming +[parent_edge]\n",
    "        # delete self and all edges\n",
    "        for edge in edges[funcall].outgoing:\n",
    "            edges[edge.target].incoming = list(filter(lambda e: e.source != funcall, edges[edge.target].incoming))\n",
    "        edges[parent].outgoing = list(filter(lambda e: e.target != funcall, edges[parent].outgoing))\n",
    "        nodes.pop(funcall)\n",
    "        edges.pop(funcall)\n",
    "        graph.info.pop(funcall)\n",
    "\n",
    "\n",
    "    # Lambda:\n",
    "    for lam in [n for n, v in nodes.items() if v == 'Lambda']:\n",
    "        # attach body node to parent and vice versa\n",
    "        if len(edges[lam].incoming) > 0:\n",
    "            parent = edges[lam].incoming[0].source\n",
    "            body_node = [e.target for e in edges[lam].outgoing if e.code == 'body'][0]\n",
    "            parent_edge = Edge(parent, body_node, edges[lam].incoming[0].code)\n",
    "            edges[parent].outgoing = edges[parent].outgoing + [parent_edge]\n",
    "            edges[body_node].incoming = edges[body_node].incoming + [parent_edge]\n",
    "        # delete self and edges\n",
    "        for edge in edges[lam].outgoing:\n",
    "            edges[edge.target].incoming = list(filter(lambda e: e.source != lam, edges[edge.target].incoming))\n",
    "        edges[parent].outgoing = list(filter(lambda e: e.target != lam, edges[parent].outgoing))\n",
    "        edges.pop(lam)\n",
    "        nodes.pop(lam)\n",
    "        graph.info.pop(lam)\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dotfile(graph, filename):\n",
    "    nodes = graph.nodes\n",
    "    edges = graph.edges\n",
    "    \n",
    "    file = open(filename, 'w')\n",
    "    file.write('digraph{ \\n ratio=\"compress\" \\n size=8 \\n margin=\"0.0,0.0\"\\n')\n",
    "    \n",
    "    for name, func in nodes.items():\n",
    "        file.write(re.sub( r'[\\(\\)]' ,'',name) + \" [style=rounded,shape=box,label=<<b>\"+func+\"</b>>]\\n\")\n",
    "    for _, edgelist in edges.items():\n",
    "        for edge in edgelist.incoming:\n",
    "            file.write(re.sub( r'[\\(\\)]' ,'',edge.source) + ' -> ' + re.sub( r'[\\(\\)]' ,'',edge.target) + ' [label=\"' + re.sub( r'[\\(\\)]' ,'',edge.code) + '\"];\\n')\n",
    "    file.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_adaptions_assertions(graph):\n",
    "    nodes = graph.nodes\n",
    "    edges = graph.edges\n",
    "    \n",
    "    # prior expectations still met\n",
    "    assumptions_checker(graph)\n",
    "    \n",
    "    for node in nodes:\n",
    "        assert len(edges[node].incoming) < 2, 'All nodes only feed at most one other node'\n",
    "    \n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_userfuncs(graph):\n",
    "    nodes = graph.nodes\n",
    "    edges = graph.edges\n",
    "    \n",
    "    userfuncs = [n for n, v in nodes.items() if v == 'UserFun']\n",
    "    \n",
    "    def desc(node):\n",
    "        return flatten([[e.target] + desc(e.target) for e in edges[node].outgoing])\n",
    "#         return [node] + flatten([desc(e.target) for e in edges[node].outgoing])\n",
    "    \n",
    "    for uf in userfuncs:\n",
    "        bundle = set(desc(uf))\n",
    "#         print(bundle)\n",
    "        if all([(nodes[n] in ['Param', 'UserFun'] or nodes[n].startswith('Value') or nodes[n].startswith('Get')) for n in bundle]):\n",
    "            for node in bundle:\n",
    "                if nodes[node] == 'Param':\n",
    "                    farinc = [e for e in edges[node].incoming if e.source not in bundle]\n",
    "                    if len(farinc) > 0:\n",
    "                        edges[node].incoming = farinc\n",
    "                    else:\n",
    "                        nodes.pop(node)\n",
    "                        edges.pop(node)\n",
    "                        graph.info.pop(node)\n",
    "                else:\n",
    "                    nodes.pop(node)\n",
    "                    edges.pop(node)\n",
    "                    graph.info.pop(node)\n",
    "            edges[uf].outgoing = []\n",
    "        else:\n",
    "            print(bundle)\n",
    "            print([nodes[n] for n in bundle])\n",
    "    return True          \n",
    "                        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_params(graph):\n",
    "    nodes = graph.nodes\n",
    "    edges = graph.edges\n",
    "    info = graph.info\n",
    "    \n",
    "    params = [n for n, v in nodes.items() if v == 'Param' and len(edges[n].incoming) > 1]\n",
    "    \n",
    "    #TODO: more foolproof system for coming up with new names of nodes\n",
    "    for param in params: \n",
    "        for parent in [e.source for e in edges[param].incoming]:\n",
    "            new_name = 'n' + str(len(nodes.keys()) + 40)\n",
    "            nodes[new_name] = 'Param'\n",
    "            info[new_name] = info[param]\n",
    "            new_edge = Edge(parent, new_name, [e.code for e in edges[parent].outgoing if e.target == param][0])\n",
    "            edges[new_name] = EdgeList([new_edge], [])\n",
    "            edges[parent].outgoing = [new_edge] + [e for e in edges[parent].outgoing if e.target != param]\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must come last from current selection\n",
    "# def reversio(graph):\n",
    "#     edges = graph.edges\n",
    "#     for node in edges.keys():\n",
    "#         edges[node] = EdgeList(edges[node].outgoing, edges[node].incoming)\n",
    "#     print('hi')\n",
    "#     return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started with:  21 graphs. \n",
      "Passed checks: 16\n",
      "\n",
      "\n",
      "Dropping wrappers starting with:  16 graphs. \n",
      "Passed checks: 16\n",
      "Passed checks: 0\n"
     ]
    }
   ],
   "source": [
    "printeddir = liftdir + \"/printed\"\n",
    "allfs =  os.listdir(printeddir)\n",
    "allfs = [os.path.join(printeddir,x) for x in allfs if \n",
    "            os.path.isfile(os.path.join(printeddir,x)) and x.endswith('v2.txt')]\n",
    "\n",
    "graphs = []\n",
    "\n",
    "for file in allfs:\n",
    "    graph = read_and_format(file)\n",
    "#     print(file, assert_assumptions(graph))\n",
    "    graphs.append(graph)\n",
    "\n",
    "working_graphs = [graph for graph in graphs if assert_assumptions(graph) == True]\n",
    "print(\"Started with: \", len(graphs), \"graphs. \\nPassed checks:\", len(working_graphs))\n",
    "# print(\"\\nFailed: \\n\", '\\n'.join([f + \":\\n    Cause: \" + assert_assumptions(g) for (g, f) in zip(graphs, allfs) if assert_assumptions(g) != True]))\n",
    "\n",
    "streamlined_graphs = [graph for graph in working_graphs if drop_wrappers(graph)]\n",
    "\n",
    "working_streamlined_graphs = [graph for graph in graphs if assert_assumptions(graph) == True]\n",
    "print(\"\\n\\nDropping wrappers starting with: \", len(streamlined_graphs), \"graphs. \\nPassed checks:\", len(working_streamlined_graphs))\n",
    "\n",
    "for graph, fn in zip(graphs, allfs):\n",
    "    fn = fn.split('.')[0] + '.dot'\n",
    "    make_dotfile(graph, fn)\n",
    "#     print(\"\\ndot -Tpdf \"+fn+\" -o \"+fn.split('.')[0]+\".pdf\")\n",
    "    \n",
    "\n",
    "# TODO: Fix duplicate params/collapse userfuncs\n",
    "curr = [g for g in working_streamlined_graphs if collapse_userfuncs(g)]\n",
    "# curr = [g for g in curr if duplicate_params(g)]\n",
    "\n",
    "# print(\"\\nCollapsed Userfuncs and expanded params\")\n",
    "print(\"Passed checks:\", len([1 for g in graphs if assert_assumptions(graph) == True]))\n",
    "\n",
    "for graph, fn in zip(graphs, allfs):\n",
    "    fn = fn.split('.')[0] + 'woUFC.dot'\n",
    "    make_dotfile(graph, fn)\n",
    "#     print(\"\\ndot -Tpdf \"+fn+\" -o \"+fn.split('.')[0]+\".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Array (len = N)', 'Array (len = N)', 'Scalar float (size = 4)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = graphs[0]\n",
    "ni = g.info['n1(1)']\n",
    "c = [s.replace('}','').strip() for s in ni.split('{')]\n",
    "[s for s in c if s != 'ParamUnknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(flatten(flatten([[clean_type(info) for k, info in g.info.items() if g.nodes[k] == 'Param'] for g in graphs])))\n",
    "\n",
    "dot_graph = graphs[5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n1(1)': 'ParamUnknown{    Array (len = N) {        Scalar float (size = 4)    }}',\n",
       " 'n3(1)': '0.0f',\n",
       " 'n5(1)': '',\n",
       " 'n7(1)': 'abs',\n",
       " 'n8(1)': '',\n",
       " 'n10(1)': 'add'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Get (0)', 'Map', 'Param', 'Reduce', 'Transpose', 'UserFun', 'Value', 'Zip'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(flatten([g.nodes.values() for g in working_streamlined_graphs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "class Undef(Data):\n",
    "    pass\n",
    "\n",
    "class Unknown(Data):\n",
    "    pass\n",
    "\n",
    "class Tuple(Data):\n",
    "    def __init__(self, length, subdatals = []):\n",
    "        self.length = length\n",
    "        self.subdatals = subdatals\n",
    "        \n",
    "    def add_subdata(subdata):\n",
    "        self.subdatals += subdata\n",
    "\n",
    "class Scalar(Data):\n",
    "    def __init__(self, kind = 'float', size : int = 4):\n",
    "        self.size = 4\n",
    "        self.kind = kind\n",
    "\n",
    "class Vector(Data):\n",
    "    def __init__(self, length, subdata):\n",
    "        self.length = length\n",
    "        self.subdata = subdata\n",
    "        \n",
    "class Array(Data):\n",
    "    def __init__(self, length, subdata):\n",
    "        self.length = length\n",
    "        self.subdata = subdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_type(info):\n",
    "    c = [s.replace('}','').strip() for s in info.split('{')]\n",
    "    return [s for s in c if s != 'ParamUnknown']\n",
    "\n",
    "def get_type(typelist):\n",
    "    head = typelist[0]\n",
    "    print(head)\n",
    "    if head.startswith('Scalar'):\n",
    "        assert len(typelist) == 1, 'Scalar is last'\n",
    "        kind = re.findall(r'Scalar ([a-zA-Z]+) ', head)[0]\n",
    "        size = re.findall(r'size = ([0-9a-zA-Z]+)', head)[0]\n",
    "        return Scalar(kind, size)\n",
    "    if head == 'UndefType':\n",
    "        return Undef()\n",
    "    if head.startswith('Vector'):\n",
    "        length = re.findall(r'len = ([0-9a-zA-Z]+)', head)[0]\n",
    "        subtype = get_type(typelist[1:])\n",
    "        return Vector(length, subtype)\n",
    "    if head.startswith('Array'):\n",
    "        length = re.findall(r'len = ([0-9a-zA-Z]+)', head)[0]\n",
    "        subtype = get_type(typelist[1:])\n",
    "        return Array(length, subtype)\n",
    "    if head.startswith('Tuple'):\n",
    "        tuple_types =[x.strip() for x in typelist[1].split('-')]\n",
    "        ret_tuple = Tuple(len(tuple_types))\n",
    "        for x in tuple_types:\n",
    "            ret_tuple.add_subdata(get_type([x]))\n",
    "        return ret_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array (len = N)\n",
      "Array (len = N)\n",
      "Scalar float (size = 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Scalar at 0x111600048>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_type(clean_type(ni)).subdata.subdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Get (0)',\n",
    " 'Map',\n",
    " 'Param',\n",
    " 'Reduce', \n",
    " 'Transpose',\n",
    " 'UserFun', \n",
    " 'Value', \n",
    " 'Zip'}\n",
    "\n",
    "Param\n",
    "Value\n",
    "\n",
    "UserFun\n",
    "\n",
    "Zip\n",
    "Reduce\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 8]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = [0,1,2,3]\n",
    "ls.append(8)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = 'Param'\n",
    "\n",
    "if nt == 'Param':\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Port:\n",
    "    def __init__ (self, direction, name, rate, dearray = False):\n",
    "        self.name = name\n",
    "        self.direction = direction\n",
    "        self.rate = rate\n",
    "        self.dearray = dearray\n",
    "    def __str__(self):\n",
    "        return \"<port type='\"+self.direction+\"' name='\"+self.name+\"' rate='\"+','.join(map(str,self.rate))+\"'/>\"\n",
    "\n",
    "class Param():\n",
    "    def __init__(self, name : str, info):\n",
    "        self.name = name\n",
    "        self.data = get_type(clean_type(info))\n",
    "        self.output = [Port('out', name + '_out', [1])]\n",
    "    def __str__(self):\n",
    "        return \"<actor name='\"+self.name+\"' type='Param'>\\n\" + '\\n'.join(map(str, self.output)) + \"\\n</actor>\"\n",
    "\n",
    "class Value():\n",
    "    def __init__(self, name : str, value, er = 0):\n",
    "        self.name = name\n",
    "        self.value = value\n",
    "        self.empty_repeats = er\n",
    "        self.output = [Port('out', name + '_out', [1] + ([0] * er))]\n",
    "    def __str__(self):\n",
    "        return \"<actor name='\"+self.name+\"' type='Param'>\\n\" + '\\n'.join(map(str, self.output)) + \"\\n</actor>\"\n",
    "\n",
    "class Reduce:\n",
    "    def __init__(self, name : str):\n",
    "        self.name = name\n",
    "#         self.subfunc = subfunc\n",
    "        self.input = [Port('in', name + '_in', [1], True)]\n",
    "        self.output = [Port('out', name + '_out', [1], True)]\n",
    "    def addSingleIteration(sg):\n",
    "        self.single_iteration = sg\n",
    "    def __str__(self):\n",
    "        return \"<actor name='\"+self.name+\"' type='Reduce'>\\n\" + '\\n'.join(map(str, self.output ++ self.input)) + \"\\n</actor>\"\n",
    "\n",
    "\n",
    "class Map:\n",
    "    def __init__(self, name : str):\n",
    "        self.name = name\n",
    "#         self.subfunc = subfunc\n",
    "        self.input = [Port('in', name + '_in', [1], True)]\n",
    "        self.output = [Port('out', name + '_out', [1], True)]\n",
    "    def addSubgraph(sg):\n",
    "        self.subgraph = sg\n",
    "        self.input = sg.inputs[0]\n",
    "        self.output = sg.output\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"<actor name='\"+self.name+\"' type='Map'>\\n\" + '\\n'.join(map(str, self.output ++ self.input)) + \"\\n</actor>\"\n",
    "    \n",
    "class Zip:\n",
    "    def __init__(self, name : str):\n",
    "        self.name = name\n",
    "        self.input = [Port('in', name + '_in1', [1], True),Port('in', name + '_in2', [1], True)]\n",
    "        self.output = [Port('out', name + '_out', [1], True)]\n",
    "    def __str__(self):\n",
    "        return \"<actor name='\"+self.name+\"' type='Zip'>\\n\" + '\\n'.join(map(str, self.output ++ self.input)) + \"\\n</actor>\"\n",
    "\n",
    "class UserFun:\n",
    "    def __init__(self, name : str):\n",
    "        self.name = name\n",
    "        self.subfunc = subfunc\n",
    "        self.input = [Port('in', name + '_in', [1])]\n",
    "        self.output = [Port('out', name + '_out', [1])]\n",
    "    def __str__(self):\n",
    "        return \"<actor name='\"+self.name+\"' type='UserFun'>\\n\" + '\\n'.join(map(str, self.output ++ self.input)) + \"\\n</actor>\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n1(1)': 'Param',\n",
       " 'n3(1)': 'Value',\n",
       " 'n5(1)': 'Map',\n",
       " 'n7(1)': 'UserFun',\n",
       " 'n8(1)': 'Reduce',\n",
       " 'n10(1)': 'UserFun'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_graph.nodes\n",
    "# .replace('(', 'X').replace(')', 'X')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-840b1b74ab79>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-840b1b74ab79>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<sdf3 type=\"csdf\" version=\"1.0\"\n",
    "    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "    xsi:noNamespaceSchemaLocation=\"http://www.es.ele.tue.nl/sdf3/xsd/sdf3-csdf.xsd\">\n",
    "<applicationGraph name='autogen'>\n",
    "    <csdf name='autogen' type='autogen'>\n",
    "        <actor name='n1X1X' type='Param'>\n",
    "            <port type='out' name='n1X1X_out' rate='1'/>\n",
    "        </actor>\n",
    "        <actor name='n5X1X1' type='Dearray'>\n",
    "            <port type='in' name='n5X5X1_in' rate='1'/>\n",
    "            <port type='out' name='n5X5X1_out' rate='10'/>\n",
    "        </actor>\n",
    "        <actor name='n7X1X' type='UserFun'>\n",
    "            <port type='in' name='n7X1X_in' rate='1'/>\n",
    "            <port type='out' name='n7X1X_out' rate='1'/>\n",
    "        </actor>\n",
    "        <actor name='N10X1X' type='UserFun'>\n",
    "            <port type='in' name='N10X1X_in' rate='1,1,1,1,1,1,1,1,1,1'/>\n",
    "            <port type='out' name='N10X1X_out' rate='0,0,0,0,0,0,0,0,0,1'/>\n",
    "            <port type='in'  name='N10X1X_self_in' rate='1,1,1,1,1,1,1,1,1,1'/>\n",
    "            <port type='out' name='N10X1X_self_out' rate='1,1,1,1,1,1,1,1,1,0'/>\n",
    "        </actor>\n",
    "        <actor name='n8X1X2' type='Rearray'>\n",
    "            <port type='in' name='n8X1X2_in' rate='10'/>\n",
    "            <port type='out' name='n8X1X2_out' rate='1'/>\n",
    "        </actor>\n",
    "        <actor name='OUTPUT' type='Output'>\n",
    "            <port type='in' name='OUTPUT' rate='1'/>\n",
    "        </actor>\n",
    "        <channel name='channel_0' srcActor='n1X1X' srcPort='n1X1X_out' dstActor='n5X1X1' dstPort='n5X5X1_in' size='1' initialTokens='0'/>\n",
    "        <channel name='channel_1' srcActor='n5X1X1' srcPort='n5X1X1_out' dstActor='n7X1X' dstPort='n7X1X_08t' size='1' initialTokens='0'/>\n",
    "        <channel name='channel_2' srcActor='n7X1X' srcPort='n7X1X_out' dstActor='N10X1X' dstPort='N10X1X_in' size='1' initialTokens='0'/>\n",
    "        <channel name='channel_3' srcActor='N10X1X' srcPort='N10X1X_self_out' dstActor='N10X1X' dstPort='N10X1X_self_in' size='1' initialTokens='1'/>\n",
    "        <channel name='channel_4' srcActor='N10X1X' srcPort='N10X1X_out' dstActor='n8X1X2' dstPort='n8X1X2_in' size='1' initialTokens='0'/>\n",
    "        <channel name='channel_5' srcActor='n8X1X2' srcPort='n8X1X2_out' dstActor='OUTPUT' dstPort='OUTPUT' size='1' initialTokens='0'/>\n",
    "    </csdf>\n",
    "\n",
    "    <csdfProperties>\n",
    "        <actorProperties actor='n1X1X'>\n",
    "            <processor type='cluster_0' default='true'>\n",
    "                <executionTime time='1'/>\n",
    "            </processor>\n",
    "        </actorProperties>\n",
    "        <actorProperties actor='n5X1X1'>\n",
    "            <processor type='cluster_0' default='true'>\n",
    "                <executionTime time='1'/>\n",
    "            </processor>\n",
    "        </actorProperties>\n",
    "        <actorProperties actor='n7X1X'>\n",
    "            <processor type='cluster_0' default='true'>\n",
    "                <executionTime time='1'/>\n",
    "            </processor>\n",
    "        </actorProperties>\n",
    "        <actorProperties actor='N10X1X'>\n",
    "            <processor type='cluster_0' default='true'>\n",
    "                <executionTime time='1,1,1,1,1,1,1,1,1,1'/>\n",
    "            </processor>\n",
    "        </actorProperties>\n",
    "        <actorProperties actor='n8X1X2'>\n",
    "            <processor type='cluster_0' default='true'>\n",
    "                <executionTime time='1'/>\n",
    "            </processor>\n",
    "        </actorProperties>\n",
    "        <actorProperties actor='OUTPUT'>\n",
    "            <processor type='cluster_0' default='true'>\n",
    "                <executionTime time='1'/>\n",
    "            </processor>\n",
    "        </actorProperties>\n",
    "    </csdfProperties>\n",
    "\n",
    "</applicationGraph>\n",
    "\n",
    "</sdf3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".replace('(', 'X').replace(')', 'X')\n",
    "\n",
    "\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<sdf3 type=\"csdf\" version=\"1.0\"\n",
    "    xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
    "    xsi:noNamespaceSchemaLocation=\"http://www.es.ele.tue.nl/sdf3/xsd/sdf3-csdf.xsd\">\n",
    "<applicationGraph name='autogen'>\n",
    "    <csdf name='autogen' type='autogen'>\n",
    "        <actor name='A' type='a'>\n",
    "            <port type='in' name='out_channel_3' rate='1,3'/>\n",
    "            <port type='out' name='in_channel_1' rate='3,5'/>\n",
    "            <port type='in'  name='out_RA' rate='1,1'/>\n",
    "            <port type='out' name='in_RA' rate='1,1'/>\n",
    "        </actor>\n",
    "        <actor name='B' type='a'>\n",
    "            <port type='in' name='out_channel_1' rate='1,1,4'/>\n",
    "            <port type='out' name='in_channel_2' rate='6,2,1'/>\n",
    "            <port type='in'  name='out_RB' rate='1,1,1'/>\n",
    "            <port type='out' name='in_RB' rate='1,1,1'/>\n",
    "        </actor>\n",
    "        <actor name='C' type='a'>\n",
    "            <port type='in' name='out_channel_2' rate='6'/>\n",
    "            <port type='out' name='in_channel_3' rate='2'/>\n",
    "            <port type='in'  name='out_RC' rate='1'/>\n",
    "            <port type='out' name='in_RC' rate='1'/>\n",
    "        </actor>\n",
    "        <channel name='channel_A' srcActor='A' srcPort='in_RA' dstActor='A' dstPort='out_RA' size='1' initialTokens='1'/>\n",
    "        <channel name='channel_B' srcActor='B' srcPort='in_RB' dstActor='B' dstPort='out_RB' size='1' initialTokens='1'/>\n",
    "        <channel name='channel_C' srcActor='C' srcPort='in_RC' dstActor='C' dstPort='out_RC' size='1' initialTokens='1'/>\n",
    "\n",
    "\n",
    "        <channel name='channel_1' srcActor='A' srcPort='in_channel_1' dstActor='B' dstPort='out_channel_1' size='1' initialTokens='0'/>\n",
    "        <channel name='channel_2' srcActor='B' srcPort='in_channel_2' dstActor='C' dstPort='out_channel_2' size='1' initialTokens='0'/>\n",
    "        <channel name='channel_3' srcActor='C' srcPort='in_channel_3' dstActor='A' dstPort='out_channel_3' size='1' initialTokens='4'/>\n",
    "    </csdf>\n",
    "\n",
    "    <csdfProperties>\n",
    "        <actorProperties actor='A'>\n",
    "            <processor type='cluster_0' default='true'>\n",
    "                <executionTime time='3,1'/>\n",
    "            </processor>\n",
    "        </actorProperties>\n",
    "        <actorProperties actor='B'>\n",
    "            <processor type='cluster_0' default='true'>\n",
    "                <executionTime time='2,1,2'/>\n",
    "            </processor>\n",
    "        </actorProperties>\n",
    "        <actorProperties actor='C'>\n",
    "            <processor type='cluster_0' default='true'>\n",
    "                <executionTime time='1'/>\n",
    "            </processor>\n",
    "        </actorProperties>\n",
    "    </csdfProperties>\n",
    "\n",
    "</applicationGraph>\n",
    "\n",
    "</sdf3>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
