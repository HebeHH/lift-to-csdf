{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ParserLexer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype management\n",
    "\n",
    "\n",
    "def magic_sv(i):\n",
    "    myopts = [10,20,30,50,5,4]\n",
    "    return random.choice(myopts)\n",
    "\n",
    "def get_sizes(ls):\n",
    "    return lambda i: ls[i]\n",
    "\n",
    "# get size vars\n",
    "def get_sizes_from_file(fn = None):\n",
    "    if fn:\n",
    "        print(\"Hello\")\n",
    "        with open(fn) as f:\n",
    "            ls = [int(x) for x in f.readlines()]\n",
    "        return get_sizes(ls)\n",
    "    return magic_sv\n",
    "    \n",
    "        \n",
    "\n",
    "# Cascade data type and size information\n",
    "  \n",
    "# TODO: Refactor so that datatype is a function of channel, not node\n",
    "# TODO: is there an okay way to rollback info gained after an Unknown?\n",
    "# TODO: This is a godawful mess please fix\n",
    "# I mean like duh\n",
    "# NOTE! Must be done before smush_rede.\n",
    "def cascade(program, sv_maker = magic_sv):\n",
    "    g = program[\"graph\"]\n",
    "    ns = g[\"nodes\"]\n",
    "    cs = g[\"channels\"]\n",
    "    nd = dict([(n.name, n) for n in ns])\n",
    "    cbsp = dict([(c.src_port, c) for c in cs])\n",
    "    svs = dict([(program['sizevars'][i], sv_maker(i)) for i in range(len(program['sizevars']))])\n",
    "    \n",
    "    visited = []\n",
    "    \n",
    "    def form_type(s):\n",
    "        op = getNextOp(s).lower()\n",
    "        if op.startswith('float'):\n",
    "            return Float()\n",
    "        elif op.startswith('int'):\n",
    "            return Int()\n",
    "        elif op.startswith('array'):\n",
    "            paras = getNextParams(s)\n",
    "            assert(len(paras) == 2)\n",
    "            sd = form_type(paras[0])\n",
    "            try:\n",
    "                l = int(paras[1].strip())\n",
    "            except:\n",
    "                l = svs[paras[1]] if 'SizeVar' not in paras[1] else magic_sv()\n",
    "            return Array(l, sd)\n",
    "        elif op.startswith('tuple'):\n",
    "            paras = getNextParams(s)\n",
    "            t = Tuple()\n",
    "            [t.add_subdata(form_type(p)) for p in paras]\n",
    "            return t\n",
    "        else: \n",
    "            return Unknown()\n",
    "    \n",
    "    in_types = [(k, form_type(x) )for k, x in program[\"inputs\"]]\n",
    "    \n",
    "    \n",
    "    dearray_by = {}\n",
    "    def def_odt(node, inc_dt):\n",
    "        try:\n",
    "            cn = getcn(node)\n",
    "            if cn == \"Param\":\n",
    "                if node.label == 'recursion':\n",
    "                    node_num = re.findall(r'[0-9]+', node.name)[0]\n",
    "                    rep_vec = dearray_by[node_num]\n",
    "                    node.input.rate = [1] * rep_vec\n",
    "                    node.output[0].rate = [1] * rep_vec\n",
    "                    node.output[1].rate = para_out_1 = [0] * (rep_vec - 1) + [1]\n",
    "                return inc_dt # e -> e\n",
    "            elif cn == \"Get\":\n",
    "                return inc_dt.subdatals[int(node.idx)]  #T(e, e, e, e...) -> e\n",
    "            elif cn == \"Transpose\":\n",
    "                sup_len = inc_dt.length\n",
    "                sub_arr = inc_dt.subdata\n",
    "                sub_len = sub_arr.length\n",
    "                return Array(sub_len, Array(sup_len, sub_arr.subdata))\n",
    "                # A( A(e, M), N ) -> A( A(e, N), M ) \n",
    "            elif cn == \"Dearray\":\n",
    "                node_num = re.findall(r'[0-9]+', node.name)[0]\n",
    "                node.output.rate = [inc_dt.length]\n",
    "                dearray_by[node_num] = inc_dt.length\n",
    "                print(\"DEARRAY \", node_num)\n",
    "                return inc_dt.subdata # A(e, N) -> e\n",
    "            elif cn == \"Rearray\":\n",
    "                node_num = re.findall(r'[0-9]+', node.name)[0]\n",
    "                new_len = 1 if node.masternode.startswith(\"Reduce\") else dearray_by[node_num]\n",
    "                node.input.rate = [new_len]\n",
    "                return Array(new_len, inc_dt) # e -> A(e, ?)\n",
    "            elif cn == \"Join\":\n",
    "                sup_len = inc_dt.length\n",
    "                sub_arr = inc_dt.subdata\n",
    "                sub_len = sub_arr.length\n",
    "                return Array(sub_len * sup_len,  sub_arr.subdata)\n",
    "                # A( A(e, N), M) -> A(e, N*M)\n",
    "            elif cn == \"Value\":\n",
    "                return inc_dt\n",
    "            elif cn == \"Zip\":\n",
    "                lengths = [x.length for x in inc_dt]\n",
    "                subdatas = [x.subdata for x in inc_dt]\n",
    "                assert(len(set(lengths)) == 1)\n",
    "                return Array(lengths[0], Tuple(subdatas))\n",
    "                # A(e), A(r) -> A(T(e, r))\n",
    "            elif cn == \"Mather\":\n",
    "                return inc_dt # e, e -> e    \n",
    "            elif cn == \"UserFun\":\n",
    "                return Unknown() # e -> b\n",
    "        except AttributeError as e:\n",
    "            print(\"ERROR ERROR ERROR\")\n",
    "            if e.args[0] == \"'Unknown' object has no attribute 'length'\":\n",
    "                return Unknown()\n",
    "            else:\n",
    "                raise\n",
    "        except KeyError:\n",
    "            default = 10\n",
    "            if cn == \"Param\":\n",
    "                node.input.rate = [1] * default\n",
    "                node.output[0].rate = [1] * default\n",
    "                node.output[1].rate = para_out_1 = [0] * (default - 1) + [1]\n",
    "                return inc_dt # e -> e\n",
    "            elif cn == \"Rearray\":\n",
    "                node.input.rate = [default]\n",
    "                return Array(default, inc_dt) # e -> A(e, ?)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    def push(node):\n",
    "        if node.name in visited or node == get_output_node(g):\n",
    "            return\n",
    "        visited.append(node.name)\n",
    "        assert(node.has_dt())\n",
    "        my_dt = node.get_dt()\n",
    "        print(\"Push \", node.name, getcn(node))\n",
    "        \n",
    "        output_nodes = [get_connected_node(g, out.name) for out in getout(node)]\n",
    "        output_ports = getout(node)\n",
    "        output_channels = [cbsp[p.name] for p in output_ports]\n",
    "        output_nodes2 = [nd[c.dst_act] for c in output_channels]\n",
    "        assert(output_nodes == output_nodes2)\n",
    "        print([n.name for n in output_nodes])\n",
    "        \n",
    "        for out_node in output_nodes:\n",
    "            print(out_node.name)\n",
    "            inc_nodes = [get_connected_node(g, inc.name) for inc in getin(out_node)]\n",
    "            if not all([x.has_dt() or channel_is_cyclic(x, out_node, g)\n",
    "                        for x in inc_nodes] ):\n",
    "                print(\"          \", out_node.name, \" not all\")\n",
    "                continue\n",
    "            if getcn(out_node) != 'Zip':\n",
    "                new_dt = def_odt(out_node, my_dt)\n",
    "                out_node.add_dt(new_dt)\n",
    "                push(out_node)\n",
    "            else:\n",
    "                my_dts = [get_connected_node(g, inc.name).datatype for inc in getin(out_node)]\n",
    "                new_dt = def_odt(out_node, my_dts)\n",
    "                out_node.add_dt(new_dt)\n",
    "                push(out_node)\n",
    "    \n",
    "    \n",
    "    # set types of input paramaters:\n",
    "    for k, dt in in_types:\n",
    "        param_nodes = [n for n in ns if getcn(n) == 'Param' and n.label == k]\n",
    "        assert(len(param_nodes) == 1)\n",
    "        param_node = param_nodes[0]\n",
    "        param_node.add_dt(dt)\n",
    "        push(param_node)\n",
    "    \n",
    "    return program\n",
    "\n",
    "# TODO: remove and fix actual cascade\n",
    "def add_dt_to_channels(program):\n",
    "    g = program['graph']\n",
    "    cs = g[\"channels\"]\n",
    "    nd = dict([(n.name, n) for n in g[\"nodes\"]])\n",
    "    for c in cs:\n",
    "        in_node = nd[c.src_act]\n",
    "        in_dt = in_node.get_dt()\n",
    "        c.add_dt(in_dt)\n",
    "    return program\n",
    "\n",
    "def add_datatypes(p, sizevar_file):\n",
    "    sizevar_func = get_sizes_from_file(sizevar_file)\n",
    "    cascade(p, sizevar_func)\n",
    "    add_dt_to_channels(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidying functions\n",
    "\n",
    "# Remove back-to-back Rearray/Dearray pairs\n",
    "def smush_rede(g):\n",
    "    ns = g[\"nodes\"]\n",
    "    cs = g[\"channels\"]\n",
    "    n_dict = dict([(n.name, n) for n in ns])\n",
    "    rds = [ c for c in cs if ((getcn(n_dict[c.src_act]) == \"Dearray\" \n",
    "                        and getcn(n_dict[c.dst_act]) == \"Rearray\")\n",
    "                       or (getcn(n_dict[c.src_act]) == \"Rearray\" \n",
    "                        and getcn(n_dict[c.dst_act]) == \"Dearray\"))]\n",
    "    for rd in rds:\n",
    "        src = n_dict[rd.src_act]\n",
    "        dst = n_dict[rd.dst_act]\n",
    "        assert(getcn(src) in [\"Rearray\", \"Dearray\"])\n",
    "        assert(getcn(dst) in [\"Rearray\", \"Dearray\"])\n",
    "        if src.output.rate == dst.input.rate:\n",
    "            inc_c = [c for c in cs if  c.dst_port == src.input.name][0]\n",
    "            out_c = [c for c in cs if c.src_port == dst.output.name][0]\n",
    "            assert(inc_c.datatype == out_c.datatype)\n",
    "            new_c = Channel(inc_c.src_act, out_c.dst_act, inc_c.src_port, out_c.dst_port)\n",
    "            new_c.add_dt(inc_c.datatype)\n",
    "            cs = [c for c in cs if c not in [inc_c, out_c, rd]] + [new_c]\n",
    "            ns = [n for n in ns if n not in [src, dst]]\n",
    "    g[\"nodes\"] = ns\n",
    "    g[\"channels\"] = cs\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation functions\n",
    "\n",
    "# Compile Recursive CSDF graph\n",
    "\n",
    "def exploder(methods):\n",
    "    return lambda g: explode(g, methods)\n",
    "\n",
    "def explode(graph, methods):\n",
    "    for method in methods:\n",
    "        method(graph, exploder(methods))\n",
    "    return graph\n",
    "\n",
    "\n",
    "def recursive_map(graph, explode_method):\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    def_len = 10\n",
    "    \n",
    "    # get Map nodes\n",
    "    mapnodes = [n for n in nodes if getcn(n) == \"Map\"]\n",
    "    # explode Map nodes\n",
    "    for node in mapnodes:\n",
    "        name = node.name\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [def_len])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        ra_out = node.output\n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [def_len])\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Map\")\n",
    "        \n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        nodes += subgraph[\"nodes\"]\n",
    "        nodes += [da, ra]\n",
    "        \n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        assert(len(old_in_channel) <= 1)\n",
    "        assert(len(old_out_channel) <= 1)\n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        channels += subgraph[\"channels\"]\n",
    "        so = subgraph[\"output\"].name\n",
    "        si = subgraph[\"inputs\"][0].name\n",
    "        channels += [Channel(da.name, \n",
    "                             get_node_by_port(subgraph[\"nodes\"], si).name, \n",
    "                             da_out.name, si), \n",
    "                     Channel(get_node_by_port(subgraph[\"nodes\"], so).name, \n",
    "                             ra.name, so, ra_in.name)]\n",
    "    # remove Map nodes\n",
    "    nodes = [n for n in nodes if getcn(n) != \"Map\"]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "\n",
    "def recursive_reduce(graph, explode_method):\n",
    "    def_len = 10\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    \n",
    "    # get Reduce nodes\n",
    "    reducenodes = [n for n in nodes if getcn(n).startswith(\"Reduce\")]\n",
    "    # explode Reduce nodes\n",
    "    for node in reducenodes:\n",
    "        name = node.name\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [def_len])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [1])\n",
    "        ra_out = node.output\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Reduce\")\n",
    "        \n",
    "        # make param for recursion\n",
    "        para = Param(name + \"XPARA\", \"recursion\")\n",
    "        para.input.rate = [1] * def_len\n",
    "        para_out_0 = para.new_outport([1] * def_len)\n",
    "        para_out_1 = para.new_outport([0] * (def_len - 1) + [1])\n",
    "        \n",
    "        # add nodes\n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        nodes += subgraph[\"nodes\"]\n",
    "        nodes += [da, ra, para]\n",
    "        \n",
    "        # add channels\n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        \n",
    "        si = subgraph[\"inputs\"]\n",
    "        so = subgraph[\"output\"].name\n",
    "        channels += [Channel(para.name, get_node_by_port(subgraph[\"nodes\"], si[1].name).name, \n",
    "                             para_out_0.name, si[1].name, 1),\n",
    "                     Channel(da.name, get_node_by_port(subgraph[\"nodes\"], si[0].name).name, \n",
    "                             da_out.name, si[0].name),\n",
    "                     Channel(get_node_by_port(subgraph[\"nodes\"], so).name, para.name,\n",
    "                             so, para.input.name),\n",
    "                     Channel(para.name, ra.name,\n",
    "                             para_out_1.name, ra_in.name)]\n",
    "        channels += subgraph[\"channels\"]\n",
    "        \n",
    "    # remove Reduce nodes\n",
    "    nodes = [n for n in nodes if not getcn(n).startswith(\"Reduce\")]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recursive_explode = exploder([recursive_map, recursive_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together\n",
    "def get_rec_csdf(filename, sizevar_file = None):\n",
    "    p = parse_file(filename)\n",
    "    g = p['graph']\n",
    "    recursive_explode(g)\n",
    "    add_datatypes(p, sizevar_file)\n",
    "    smush_rede(g)\n",
    "    check_correct(g)\n",
    "    csdf = get_csdf(g)\n",
    "    return p\n",
    "\n",
    "def write_csdf_from_hl(from_file, to_file):\n",
    "    write_csdf(get_rec_csdf(from_file)[\"graph\"], to_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    write_csdf_from_hl(add_cwd(\"highLevel/mmNN\"), add_cwd(\"csdf_xmls/mmNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World\n",
      "Push  n1 Param\n",
      "['n15XDA']\n",
      "n15XDA\n",
      "DEARRAY  15\n",
      "Push  n15XDA Dearray\n",
      "['n3']\n",
      "n3\n",
      "Push  n3 Param\n",
      "['n12']\n",
      "n12\n",
      "           n12  not all\n",
      "Push  n2 Param\n",
      "['n14']\n",
      "n14\n",
      "Push  n14 Transpose\n",
      "['n13XDA']\n",
      "n13XDA\n",
      "DEARRAY  13\n",
      "Push  n13XDA Dearray\n",
      "['n4']\n",
      "n4\n",
      "Push  n4 Param\n",
      "['n12']\n",
      "n12\n",
      "Push  n12 Zip\n",
      "['n11XDA']\n",
      "n11XDA\n",
      "DEARRAY  11\n",
      "Push  n11XDA Dearray\n",
      "['n7']\n",
      "n7\n",
      "Push  n7 Param\n",
      "['n9', 'n10']\n",
      "n9\n",
      "Push  n9 Get\n",
      "['n8']\n",
      "n8\n",
      "           n8  not all\n",
      "n10\n",
      "Push  n10 Get\n",
      "['n8']\n",
      "n8\n",
      "Push  n8 Mather\n",
      "['n11XRA']\n",
      "n11XRA\n",
      "Push  n11XRA Rearray\n",
      "['n6XDA']\n",
      "n6XDA\n",
      "DEARRAY  6\n",
      "Push  n6XDA Dearray\n",
      "['n5']\n",
      "n5\n",
      "Push  n5 Mather\n",
      "['n6XPARA']\n",
      "n6XPARA\n",
      "Push  n6XPARA Param\n",
      "['n5', 'n6XRA']\n",
      "n5\n",
      "n6XRA\n",
      "Push  n6XRA Rearray\n",
      "['n13XRA']\n",
      "n13XRA\n",
      "Push  n13XRA Rearray\n",
      "['n15XRA']\n",
      "n15XRA\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
