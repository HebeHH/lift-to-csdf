{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ParserLexer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidying functions\n",
    "\n",
    "# Remove back-to-back Rearray/Dearray pairs\n",
    "def compose_maps(g, *kwargs):\n",
    "#     add_dt_to_channels_g(g)\n",
    "    ns = g[\"nodes\"]\n",
    "    cs = g[\"channels\"]\n",
    "    n_dict = dict([(n.name, n) for n in ns])\n",
    "    rds = [ c for c in cs if ((getcn(n_dict[c.src_act]) == \"Dearray\" \n",
    "                        and getcn(n_dict[c.dst_act]) == \"Rearray\")\n",
    "                       or (getcn(n_dict[c.src_act]) == \"Rearray\" \n",
    "                        and getcn(n_dict[c.dst_act]) == \"Dearray\"))]\n",
    "    for rd in rds:\n",
    "        src = n_dict[rd.src_act]\n",
    "        dst = n_dict[rd.dst_act]\n",
    "        assert(getcn(src) in [\"Rearray\", \"Dearray\"])\n",
    "        assert(getcn(dst) in [\"Rearray\", \"Dearray\"])\n",
    "        if src.output.rate == dst.input.rate:\n",
    "            inc_c = [c for c in cs if  c.dst_port == src.input.name][0]\n",
    "            out_c = [c for c in cs if c.src_port == dst.output.name][0]\n",
    "            if str(inc_c.datatype) == str(out_c.datatype):\n",
    "                new_c = Channel(inc_c.src_act, out_c.dst_act, inc_c.src_port, out_c.dst_port)\n",
    "                new_c.add_dt(inc_c.datatype)\n",
    "                cs = [c for c in cs if c not in [inc_c, out_c, rd]] + [new_c]\n",
    "                ns = [n for n in ns if n not in [src, dst]]\n",
    "            else:\n",
    "                print(str(inc_c.datatype), str(out_c.datatype))\n",
    "    g[\"nodes\"] = ns\n",
    "    g[\"channels\"] = cs\n",
    "    add_dt_to_channels_g(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation functions\n",
    "\n",
    "# Compile Recursive CSDF graph\n",
    "\n",
    "def exploder(methods):\n",
    "    return lambda g: explode(g, methods)\n",
    "\n",
    "def explode(graph, methods):\n",
    "    for method in methods:\n",
    "        method(graph, exploder(methods))\n",
    "#         c\n",
    "    return graph\n",
    "\n",
    "\n",
    "def discrete_zip(graph, explode_method):\n",
    "#     add_dt_to_channels_g(graph)\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    def_len = 10\n",
    "    \n",
    "    # get Zip nodes\n",
    "    zipnodes = [n for n in nodes if getcn(n) == \"Zip\"]\n",
    "    # explode Zip nodes\n",
    "    for node in zipnodes:\n",
    "        name = node.name\n",
    "        \n",
    "        old_in_channels = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        assert(len(old_in_channels) >= 1)\n",
    "        assert(len(old_out_channel) <= 1)\n",
    "        \n",
    "        zippee = Zippee(node.name + \"XZippee\")\n",
    "        zippee.add_dt(Tuple(node.datatype.subdata.subdatals))\n",
    "        \n",
    "        \n",
    "        for din, i in zip(old_in_channels, range(len(old_in_channels))):\n",
    "            da_in = [x for x in node.input if x.name == din.dst_port][0]\n",
    "            da_out = Port(\"out\", name + \"XDA_out_x\"+str(i), [node.datatype.length])\n",
    "            da = Dearray(name + \"XDA_x\"+str(i), da_in, da_out)\n",
    "            da.datatype = din.datatype.subdata\n",
    "            din.dst_act = da.name\n",
    "            nodes.append(da)\n",
    "            channels.append(Channel(da.name, zippee.name, da_out.name, zippee.new_inport().name))\n",
    "            \n",
    "                          \n",
    "        ra_out = node.output\n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [node.datatype.length])\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Zip\")\n",
    "        ra.datatype = node.datatype\n",
    "        nodes += [ra, zippee]\n",
    "        old_out_channel[0].src_act = ra.name\n",
    "        channels.append(Channel(zippee.name, ra.name, zippee.output.name, ra.input.name))\n",
    "        \n",
    "        \n",
    "    # remove Zip nodes\n",
    "    nodes = [n for n in nodes if getcn(n) != \"Zip\"]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "\n",
    "def parallel_map(graph, explode_method, groupsize = 1):\n",
    "    def_len = 10\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    \n",
    "    # get Map nodes\n",
    "    mapnodes = [n for n in nodes if getcn(n) == (\"Map\")]\n",
    "    # explode Map nodes\n",
    "    for node in mapnodes:\n",
    "        name = node.name\n",
    "        # get channels\n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        inc_datatype = old_in_channel[0].datatype\n",
    "        \n",
    "        # make new nodes\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [node.rep])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        da.datatype = inc_datatype.subdata\n",
    "        \n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [node.rep])\n",
    "        ra_out = node.output\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Map\")\n",
    "        ra.datatype = node.datatype\n",
    "        \n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        \n",
    "        \n",
    "        # make Splitter and link to dearray\n",
    "        total_vals =  inc_datatype.length\n",
    "        routes = int(total_vals / groupsize)\n",
    "        assert( total_vals % groupsize == 0)\n",
    "        \n",
    "        spl = Splitter(name+\"XSpl\", routes, groupsize, 0)\n",
    "        spl.add_dt(inc_datatype.subdata)\n",
    "        channels += [Channel(da.name, spl.name, da_out.name, spl.input.name)]\n",
    "        \n",
    "        # make Joiner and link to Rearray        \n",
    "        jnr = Joiner(name+\"XJnr\", routes, groupsize)\n",
    "        jnr.add_dt(node.datatype.subdata)\n",
    "        channels += [Channel(jnr.name, ra.name, jnr.output.name, ra_in.name)]\n",
    "        \n",
    "        # add nodes\n",
    "        nodes += [da, ra, jnr, spl]\n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        externals = [c.src_act for c in subgraph['channels'] if c.src_act not in [n.name for n in subgraph['nodes']]]\n",
    "        externals = [n for n in nodes if n.name in externals]\n",
    "        count = 0\n",
    "        for i in range(routes):\n",
    "            count += 1\n",
    "            sg = deepcopy(subgraph, count)\n",
    "            \n",
    "            for n in externals:\n",
    "#                 print(n.name)\n",
    "                for cc in [c for c in sg['channels'] if c.src_act == n.name]:\n",
    "                    cc.name = cc.name + \"_x\" + str(count)\n",
    "                    po = n.new_outport()\n",
    "                    cc.src_port = po.name\n",
    "            \n",
    "            \n",
    "            so = sg[\"output\"].name\n",
    "            si = sg[\"inputs\"][0].name\n",
    "            \n",
    "            channels += [Channel(spl.name, \n",
    "                                 get_node_by_port(sg[\"nodes\"], si).name, \n",
    "                                 spl.output[i].name, si), \n",
    "                         Channel(get_node_by_port(sg[\"nodes\"], so).name, \n",
    "                                 jnr.name, so, jnr.input[i].name)]\n",
    "            \n",
    "            nodes += sg[\"nodes\"]\n",
    "            channels += sg[\"channels\"]\n",
    "        \n",
    "    # remove Map nodes\n",
    "    nodes = [n for n in nodes if not getcn(n)==\"Map\"]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "            \n",
    "\n",
    "\n",
    "def recursive_map(graph, explode_method):\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    def_len = 10\n",
    "    \n",
    "    # get Map nodes\n",
    "    mapnodes = [n for n in nodes if getcn(n) == \"Map\"]\n",
    "    # explode Map nodes\n",
    "    for node in mapnodes:\n",
    "#         print(node.name, getcn(node), node.datatype)\n",
    "        name = node.name\n",
    "        \n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        assert(len(old_in_channel) == 1)\n",
    "        assert(len(old_out_channel) <= 1)\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [node.rep])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        da.datatype = old_in_channel[0].datatype.subdata\n",
    "        ra_out = node.output\n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [node.rep])\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Map\")\n",
    "        ra.datatype = node.datatype\n",
    "        \n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        nodes += subgraph[\"nodes\"]\n",
    "        nodes += [da, ra]\n",
    "        \n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        channels += subgraph[\"channels\"]\n",
    "        so = subgraph[\"output\"].name\n",
    "        si = subgraph[\"inputs\"][0].name\n",
    "        channels += [Channel(da.name, \n",
    "                             get_node_by_port(subgraph[\"nodes\"], si).name, \n",
    "                             da_out.name, si), \n",
    "                     Channel(get_node_by_port(subgraph[\"nodes\"], so).name, \n",
    "                             ra.name, so, ra_in.name)]\n",
    "    # remove Map nodes\n",
    "    nodes = [n for n in nodes if getcn(n) != \"Map\"]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "\n",
    "\n",
    "def recursive_map(graph, explode_method):\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    def_len = 10\n",
    "    \n",
    "    # get Map nodes\n",
    "    mapnodes = [n for n in nodes if getcn(n) == \"Map\"]\n",
    "    # explode Map nodes\n",
    "    for node in mapnodes:\n",
    "#         print(node.name, getcn(node), node.datatype)\n",
    "        name = node.name\n",
    "        \n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        assert(len(old_in_channel) == 1)\n",
    "        assert(len(old_out_channel) <= 1)\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [node.rep])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        da.datatype = old_in_channel[0].datatype.subdata\n",
    "        ra_out = node.output\n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [node.rep])\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Map\")\n",
    "        ra.datatype = node.datatype\n",
    "        \n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        nodes += subgraph[\"nodes\"]\n",
    "        nodes += [da, ra]\n",
    "        \n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        channels += subgraph[\"channels\"]\n",
    "        so = subgraph[\"output\"].name\n",
    "        si = subgraph[\"inputs\"][0].name\n",
    "        channels += [Channel(da.name, \n",
    "                             get_node_by_port(subgraph[\"nodes\"], si).name, \n",
    "                             da_out.name, si), \n",
    "                     Channel(get_node_by_port(subgraph[\"nodes\"], so).name, \n",
    "                             ra.name, so, ra_in.name)]\n",
    "    # remove Map nodes\n",
    "    nodes = [n for n in nodes if getcn(n) != \"Map\"]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "\n",
    "def recursive_reduce(graph, explode_method):\n",
    "    def_len = 10\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    \n",
    "    # get Reduce nodes\n",
    "    reducenodes = [n for n in nodes if getcn(n).startswith(\"Reduce\")]\n",
    "    # explode Reduce nodes\n",
    "    for node in reducenodes:\n",
    "        name = node.name\n",
    "        # get channels\n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        \n",
    "        # make new nodes\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [node.rep])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        da.datatype = old_in_channel[0].datatype.subdata\n",
    "        \n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [1])\n",
    "        ra_out = node.output\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Reduce\")\n",
    "        ra.datatype = node.datatype\n",
    "        \n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        \n",
    "        # make param for recursion\n",
    "        para = Param(name + \"XPARA\", \"recursion\")\n",
    "        para.datatype = node.datatype.subdata\n",
    "        para.input.rate = [1] * node.rep\n",
    "        para_out_0 = para.new_outport([1] * node.rep)\n",
    "        para_out_1 = para.new_outport([0] * (node.rep - 1) + [1])\n",
    "        \n",
    "        # add nodes\n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        nodes += subgraph[\"nodes\"]\n",
    "        nodes += [da, ra, para]\n",
    "        \n",
    "        # add channels\n",
    "        si = subgraph[\"inputs\"]\n",
    "        so = subgraph[\"output\"].name\n",
    "        channels += [Channel(para.name, get_node_by_port(subgraph[\"nodes\"], si[1].name).name, \n",
    "                             para_out_0.name, si[1].name, 1),\n",
    "                     Channel(da.name, get_node_by_port(subgraph[\"nodes\"], si[0].name).name, \n",
    "                             da_out.name, si[0].name),\n",
    "                     Channel(get_node_by_port(subgraph[\"nodes\"], so).name, para.name,\n",
    "                             so, para.input.name),\n",
    "                     Channel(para.name, ra.name,\n",
    "                             para_out_1.name, ra_in.name)]\n",
    "        channels += subgraph[\"channels\"]\n",
    "        \n",
    "    # remove Reduce nodes\n",
    "    nodes = [n for n in nodes if not getcn(n).startswith(\"Reduce\")]\n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepcopy(g, i):\n",
    "    i = str(i)\n",
    "    newg = copy.deepcopy(g)\n",
    "    nodes = newg['nodes']\n",
    "    nodenames = [n.name for n in nodes]\n",
    "    for channel in newg['channels']:\n",
    "        if channel.src_act in nodenames and channel.dst_act in nodenames:\n",
    "            channel.name = channel.name + \"_x\" + i\n",
    "        if channel.src_act in nodenames:\n",
    "            channel.src_act = channel.src_act + \"_x\" + i\n",
    "            channel.src_port = channel.src_port + \"_x\" + i\n",
    "        if channel.dst_act in nodenames:\n",
    "            channel.dst_act = channel.dst_act + \"_x\" + i\n",
    "            channel.dst_port = channel.dst_port + \"_x\" + i\n",
    "    for node in nodes:\n",
    "        node.name = node.name + \"_x\" + i\n",
    "        for port in getports(node):\n",
    "            port.name = port.name + \"_x\" + i\n",
    "    return newg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_reducer(graph, explode_method, groupsize = 1):\n",
    "    def_len = 10\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    \n",
    "    # get Reduce nodes\n",
    "    reducenodes = [n for n in nodes if getcn(n) == (\"Reduce\")]\n",
    "    # explode Reduce nodes\n",
    "    for node in reducenodes:\n",
    "        name = node.name\n",
    "        # get channels\n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        inc_datatype = old_in_channel[0].datatype\n",
    "        \n",
    "        # make new nodes\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [node.rep])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        da.datatype = inc_datatype.subdata\n",
    "        \n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [1])\n",
    "        ra_out = node.output\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Reduce\")\n",
    "        ra.datatype = node.datatype\n",
    "        \n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        \n",
    "        # make initial value\n",
    "        ival = Value(name + \"XInitVal\", node.initval, inc_datatype.subdata)\n",
    "        ival.add_dt(inc_datatype.subdata)\n",
    "        \n",
    "#         print(inc_datatype)\n",
    "        \n",
    "        # make Splitter and link to dearray\n",
    "        total_vals =  inc_datatype.length\n",
    "        routes = int(total_vals / groupsize)\n",
    "        remaining = total_vals % groupsize\n",
    "        \n",
    "        spl = Splitter(name+\"XSpl\", routes, groupsize, remaining)\n",
    "        spl.add_dt(inc_datatype.subdata)\n",
    "        channels += [Channel(da.name, spl.name, da_out.name, spl.input.name)]\n",
    "        \n",
    "        # add nodes\n",
    "        nodes += [da, ra, ival, spl]\n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        datavals = [(spl.name, p.name) for p in spl.output] + [(ival.name, ival.output.name)]\n",
    "        count = 0\n",
    "        while len(datavals) > 1:\n",
    "            sg = deepcopy(subgraph, count)\n",
    "            count += 1\n",
    "            nodes += sg[\"nodes\"]\n",
    "            channels += sg[\"channels\"]\n",
    "            # add channels\n",
    "            in1 = datavals.pop(0)\n",
    "            in2 = datavals.pop(0)\n",
    "            si = sg[\"inputs\"]\n",
    "            \n",
    "            channels += [Channel(in1[0], get_node_by_port(sg[\"nodes\"], si[0].name).name, \n",
    "                                 in1[1], si[0].name),\n",
    "                         Channel(in2[0], get_node_by_port(sg[\"nodes\"], si[1].name).name, \n",
    "                                 in2[1], si[1].name)]\n",
    "            so = sg[\"output\"].name\n",
    "            datavals.append((get_node_by_port(sg[\"nodes\"], so).name, so))\n",
    "        in1 = datavals.pop()\n",
    "        channels.append(Channel(in1[0], ra.name, \n",
    "                                 in1[1], ra_in.name))\n",
    "        \n",
    "    # remove Reduce nodes\n",
    "    nodes = [n for n in nodes if not getcn(n)==\"Reduce\"]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "            \n",
    "\n",
    "\n",
    "parallel_reduce = lambda a, b: parallel_reducer(a, b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recursive_explode = exploder([recursive_map, recursive_reduce])\n",
    "parallel_explode = exploder([parallel_reduce, recursive_map, recursive_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together\n",
    "def fullfettle(filename, method, sizevar_file = None):\n",
    "    p = parse_file(filename, sizevar_file)\n",
    "    g = p['graph']\n",
    "    method(g)\n",
    "    add_dt_to_channels(p)\n",
    "    check_correct(g)\n",
    "    return p\n",
    "\n",
    "def smush_rede(p):\n",
    "    compose_maps(p['graph'])\n",
    "    add_dt_to_channels(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "# Put together\n",
    "def get_rec_csdf(filename, sizevar_file = None):\n",
    "    return fullfettle(filename, recursive_explode, sizevar_file)\n",
    "def get_parallel_csdf(filename, sizevar_file = None):\n",
    "    return fullfettle(filename, parallel_explode, sizevar_file)\n",
    "\n",
    "def write_csdf_from_hl(from_file, to_file):\n",
    "    write_csdf(get_rec_csdf(from_file)[\"graph\"], to_file)\n",
    "\n",
    "def try_do(filename, methods, sizevar_file = None):\n",
    "    try:\n",
    "        p = parse_file(filename, sizevar_file)\n",
    "        g = p['graph']\n",
    "        exploder(methods)(g)\n",
    "        add_dt_to_channels(p)\n",
    "        check_correct(g)\n",
    "        return(p)\n",
    "    except Exception as e:\n",
    "        print(\"\\nCouldn't get CSDF for \" + filename)\n",
    "        print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recmethods = [discrete_zip, parallel_map, recursive_reduce]\n",
    "p = try_do(\"highLevel/mydotsmol\", recmethods, [3] * 10)\n",
    "k = p['graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n1: Param\n",
      "n2: Param\n",
      "n3: Param\n",
      "n4: Param\n",
      "n10XDA_x0: Dearray\n",
      "n10XDA_x1: Dearray\n",
      "n10XRA: Rearray\n",
      "n10XZippee: Zippee\n",
      "n9XDA: Dearray\n",
      "n9XRA: Rearray\n",
      "n9XJnr: Joiner\n",
      "n9XSpl: Splitter\n",
      "n5_x1: Param\n",
      "n7_x1: Get\n",
      "n8_x1: Get\n",
      "n6_x1: Mather\n",
      "n5_x2: Param\n",
      "n7_x2: Get\n",
      "n8_x2: Get\n",
      "n6_x2: Mather\n",
      "n5_x3: Param\n",
      "n7_x3: Get\n",
      "n8_x3: Get\n",
      "n6_x3: Mather\n",
      "n11XDA: Dearray\n",
      "n11XRA: Rearray\n",
      "n11XPARA: Param\n",
      "[('n1', 'n11XDA', 'Array (3, Array (3, Float))')]\n",
      "[('n11XPARA', 'n4', 'Array (3, Float)')]\n",
      "[('n11XDA', 'n3', 'Array (3, Float)')]\n",
      "[('n9XRA', 'n11XPARA', 'Array (3, Float)')]\n",
      "[('n11XPARA', 'n11XRA', 'Array (3, Float)')]\n",
      "[('n3', 'n10XDA_x0', 'Array (3, Float)')]\n",
      "[('n4', 'n10XDA_x1', 'Array (3, Float)')]\n",
      "[('n10XRA', 'n9XDA', 'Array (3, Tuple (Float, Float))')]\n",
      "[('n10XDA_x0', 'n10XZippee', 'Float')]\n",
      "[('n10XDA_x1', 'n10XZippee', 'Float')]\n",
      "[('n10XZippee', 'n10XRA', 'Tuple (Float, Float)')]\n",
      "[('n9XDA', 'n9XSpl', 'Tuple (Float, Float)')]\n",
      "[('n9XJnr', 'n9XRA', 'Float')]\n",
      "[('n9XSpl', 'n5_x1', 'Tuple (Float, Float)')]\n",
      "[('n6_x1', 'n9XJnr', 'Float')]\n",
      "[('n5_x1', 'n7_x1', 'Tuple (Float, Float)')]\n",
      "[('n7_x1', 'n6_x1', 'Float')]\n",
      "[('n5_x1', 'n8_x1', 'Tuple (Float, Float)')]\n",
      "[('n8_x1', 'n6_x1', 'Float')]\n",
      "[('n9XSpl', 'n5_x2', 'Tuple (Float, Float)')]\n",
      "[('n6_x2', 'n9XJnr', 'Float')]\n",
      "[('n5_x2', 'n7_x2', 'Tuple (Float, Float)')]\n",
      "[('n7_x2', 'n6_x2', 'Float')]\n",
      "[('n5_x2', 'n8_x2', 'Tuple (Float, Float)')]\n",
      "[('n8_x2', 'n6_x2', 'Float')]\n",
      "[('n9XSpl', 'n5_x3', 'Tuple (Float, Float)')]\n",
      "[('n6_x3', 'n9XJnr', 'Float')]\n",
      "[('n5_x3', 'n7_x3', 'Tuple (Float, Float)')]\n",
      "[('n7_x3', 'n6_x3', 'Float')]\n",
      "[('n5_x3', 'n8_x3', 'Tuple (Float, Float)')]\n",
      "[('n8_x3', 'n6_x3', 'Float')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sizevars': ['K', 'N'],\n",
       " 'inputs': [('R', 'ArrayType(ArrayType(Float, K), N)'),\n",
       "  ('I', 'ArrayType(Float, K)')],\n",
       " 'code': '\\n  ArrayType(ArrayType(Float, K), N),\\n  ArrayType(Float, K),\\n  (R, I) =>\\n  \\tR :>> Reduce(\\\\((A, B) =>\\n  \\t  \\t    Map(fun(x => \\n  \\t  \\t        \\t\\tmult(Get(x, 0), Get(x, 1))))\\n  \\t  \\t    $ Zip(A, B)), I)\\n',\n",
       " 'graph': {'nodes': [<__main__.Param at 0x106e5d750>,\n",
       "   <__main__.Param at 0x106e5d910>,\n",
       "   <__main__.Param at 0x106e67fd0>,\n",
       "   <__main__.Param at 0x106e67ed0>,\n",
       "   <__main__.Dearray at 0x106dff6d0>,\n",
       "   <__main__.Dearray at 0x106dff590>,\n",
       "   <__main__.Rearray at 0x106e01050>,\n",
       "   <__main__.Zippee at 0x106dffad0>,\n",
       "   <__main__.Dearray at 0x106e01810>,\n",
       "   <__main__.Rearray at 0x106e014d0>,\n",
       "   <__main__.Joiner at 0x106e01190>,\n",
       "   <__main__.Splitter at 0x106e01410>,\n",
       "   <__main__.Param at 0x106e4d050>,\n",
       "   <__main__.Get at 0x106dff890>,\n",
       "   <__main__.Get at 0x106dff490>,\n",
       "   <__main__.Mather at 0x106eb0410>,\n",
       "   <__main__.Param at 0x106e5d090>,\n",
       "   <__main__.Get at 0x106e5d3d0>,\n",
       "   <__main__.Get at 0x106e75610>,\n",
       "   <__main__.Mather at 0x106e75710>,\n",
       "   <__main__.Param at 0x106e4d550>,\n",
       "   <__main__.Get at 0x106e4d5d0>,\n",
       "   <__main__.Get at 0x106e4d750>,\n",
       "   <__main__.Mather at 0x106e4dad0>,\n",
       "   <__main__.Dearray at 0x106eb0890>,\n",
       "   <__main__.Rearray at 0x106dff190>,\n",
       "   <__main__.Param at 0x106dff390>],\n",
       "  'channels': [<__main__.Channel at 0x106e81ed0>,\n",
       "   <__main__.Channel at 0x106dff850>,\n",
       "   <__main__.Channel at 0x106dff750>,\n",
       "   <__main__.Channel at 0x106dffc10>,\n",
       "   <__main__.Channel at 0x106dffcd0>,\n",
       "   <__main__.Channel at 0x106e81b10>,\n",
       "   <__main__.Channel at 0x106e81c90>,\n",
       "   <__main__.Channel at 0x106e81cd0>,\n",
       "   <__main__.Channel at 0x106dff1d0>,\n",
       "   <__main__.Channel at 0x106dffa90>,\n",
       "   <__main__.Channel at 0x106e81d10>,\n",
       "   <__main__.Channel at 0x106e01ad0>,\n",
       "   <__main__.Channel at 0x106e18810>,\n",
       "   <__main__.Channel at 0x106e01f90>,\n",
       "   <__main__.Channel at 0x106e18e50>,\n",
       "   <__main__.Channel at 0x106eb0690>,\n",
       "   <__main__.Channel at 0x106eb0bd0>,\n",
       "   <__main__.Channel at 0x106eb0790>,\n",
       "   <__main__.Channel at 0x106eb0290>,\n",
       "   <__main__.Channel at 0x106dffc50>,\n",
       "   <__main__.Channel at 0x106e81310>,\n",
       "   <__main__.Channel at 0x106e75cd0>,\n",
       "   <__main__.Channel at 0x106d43790>,\n",
       "   <__main__.Channel at 0x106d6bf50>,\n",
       "   <__main__.Channel at 0x1063c30d0>,\n",
       "   <__main__.Channel at 0x106e4d210>,\n",
       "   <__main__.Channel at 0x106e4d310>,\n",
       "   <__main__.Channel at 0x106e4dc10>,\n",
       "   <__main__.Channel at 0x106e4de50>,\n",
       "   <__main__.Channel at 0x106e4ded0>,\n",
       "   <__main__.Channel at 0x106e4df50>],\n",
       "  'inputs': [<__main__.Port at 0x106e5d310>, <__main__.Port at 0x106e5d690>],\n",
       "  'output': <__main__.Port at 0x106e81e10>}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printgraph_simple(k)\n",
    "add_dt_to_channels(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n1',\n",
       " 'n11XPARA',\n",
       " 'n11XDA',\n",
       " 'n9XRA',\n",
       " 'n11XPARA',\n",
       " 'n3',\n",
       " 'n4',\n",
       " 'n10XRA',\n",
       " 'n10XDA_x0',\n",
       " 'n10XDA_x1',\n",
       " 'n10XZippee',\n",
       " 'n9XDA',\n",
       " 'n9XJnr',\n",
       " 'n9XSpl',\n",
       " 'n6_x1',\n",
       " 'n5_x1',\n",
       " 'n7_x1',\n",
       " 'n5_x1',\n",
       " 'n8_x1',\n",
       " 'n9XSpl',\n",
       " 'n6_x2',\n",
       " 'n5_x2',\n",
       " 'n7_x2',\n",
       " 'n5_x2',\n",
       " 'n8_x2',\n",
       " 'n9XSpl',\n",
       " 'n6_x3',\n",
       " 'n5_x3',\n",
       " 'n7_x3',\n",
       " 'n5_x3',\n",
       " 'n8_x3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[c.src_act for c in k['channels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "100 7\n",
      "100 7\n",
      "51\n",
      "100 7\n",
      "100 7\n",
      "101\n",
      "100 7\n",
      "100 7\n",
      "151\n",
      "100 7\n",
      "100 7\n",
      "201\n",
      "100 7\n",
      "100 7\n",
      "251\n",
      "100 7\n",
      "100 7\n",
      "301\n",
      "100 7\n",
      "100 7\n",
      "351\n",
      "100 7\n",
      "100 7\n",
      "401\n",
      "100 7\n",
      "100 7\n",
      "451\n",
      "100 7\n",
      "100 7\n",
      "501\n",
      "100 7\n",
      "100 7\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "\n",
    "parreducemethods = [parallel_reduce, recursive_map, recursive_reduce]\n",
    "parmethods = [parallel_reduce, parallel_map, recursive_reduce]\n",
    "naivemethods = [recursive_map, recursive_reduce]\n",
    "parmapmethods = [parallel_map, recursive_reduce]\n",
    "ls = range(1, 502, 50)\n",
    "naive_ct = []\n",
    "par_ct = []\n",
    "for i in ls:\n",
    "    print(i)\n",
    "    x = %timeit -n100 -q -o try_do(\"highLevel/asum\", naivemethods, [i])\n",
    "    naive_ct.append(sum(x.all_runs)/x.loops/x.repeat)\n",
    "    print(x.loops, x.repeat)\n",
    "    x = %timeit -n100 -q -o try_do(\"highLevel/asum\", parmapmethods, [i])\n",
    "    par_ct.append(sum(x.all_runs)/x.loops/x.repeat)\n",
    "    print(x.loops, x.repeat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0006328892199998596,\n",
       " 0.000539281869999968,\n",
       " 0.0005344014514285586,\n",
       " 0.0005433514571427622,\n",
       " 0.0005654523071429399,\n",
       " 0.0006011206785717604,\n",
       " 0.0006012267200001784,\n",
       " 0.0005926037014280284,\n",
       " 0.0005577584542860287,\n",
       " 0.0005507703571421579,\n",
       " 0.0005213702457142843]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0007193738171425983,\n",
       " 0.008118547714285895,\n",
       " 0.01769014657857156,\n",
       " 0.03611940392142872,\n",
       " 0.045488045904285825,\n",
       " 0.05487110860142853,\n",
       " 0.07468838649571466,\n",
       " 0.08596628359142836,\n",
       " 0.10680891441714364,\n",
       " 0.11755385689142875,\n",
       " 0.14108672793428534]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tst5(k):\n",
    "    return k**k\n",
    "x = %timeit  -q -o tst5(9)\n",
    "sum(x.all_runs)/x.loops/x.repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.550718842857188e-07 3.137222230000134e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.3418676469999582,\n",
       "  0.3617993300000535,\n",
       "  0.4372193699999798,\n",
       "  0.3935758599999417,\n",
       "  0.3137222230000134,\n",
       "  0.316869587000042,\n",
       "  0.3204491730000427],\n",
       " 1000000,\n",
       " 7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sum(x.all_runs)/x.loops/x.repeat,x.best)\n",
    "x.all_runs, x.loops, x.repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     write_csdf_from_hl(add_cwd(\"highLevel/mmNN\"), add_cwd(\"csdf_xmls/mmNN\"))\n",
    "    \n",
    "def testr():\n",
    "    return get_rec_csdf(add_cwd(\"highLevel/mmNN\"))\n",
    "def testp():\n",
    "    return get_parallel_csdf(add_cwd(\"highLevel/mmNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = get_rec_csdf(add_cwd(\"highLevel/mydot\"), [10,10,10,10,10])\n",
    "zz = k['graph']['nodes'][10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zz.datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sfile.txt', 'w') as f:\n",
    "    f.write('\\n'.join(['10']*5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = testr()['graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
