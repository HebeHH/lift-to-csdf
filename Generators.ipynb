{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ParserLexer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidying functions\n",
    "\n",
    "# Remove back-to-back Rearray/Dearray pairs\n",
    "def compose_maps(g, *kwargs):\n",
    "#     add_dt_to_channels_g(g)\n",
    "    ns = g[\"nodes\"]\n",
    "    cs = g[\"channels\"]\n",
    "    n_dict = dict([(n.name, n) for n in ns])\n",
    "    rds = [ c for c in cs if ((getcn(n_dict[c.src_act]) == \"Dearray\" \n",
    "                        and getcn(n_dict[c.dst_act]) == \"Rearray\")\n",
    "                       or (getcn(n_dict[c.src_act]) == \"Rearray\" \n",
    "                        and getcn(n_dict[c.dst_act]) == \"Dearray\"))]\n",
    "    for rd in rds:\n",
    "        src = n_dict[rd.src_act]\n",
    "        dst = n_dict[rd.dst_act]\n",
    "        assert(getcn(src) in [\"Rearray\", \"Dearray\"])\n",
    "        assert(getcn(dst) in [\"Rearray\", \"Dearray\"])\n",
    "        if src.output.rate == dst.input.rate:\n",
    "            inc_c = [c for c in cs if  c.dst_port == src.input.name][0]\n",
    "            out_c = [c for c in cs if c.src_port == dst.output.name][0]\n",
    "            if str(inc_c.datatype) == str(out_c.datatype):\n",
    "                new_c = Channel(inc_c.src_act, out_c.dst_act, inc_c.src_port, out_c.dst_port)\n",
    "                new_c.add_dt(inc_c.datatype)\n",
    "                cs = [c for c in cs if c not in [inc_c, out_c, rd]] + [new_c]\n",
    "                ns = [n for n in ns if n not in [src, dst]]\n",
    "            else:\n",
    "                print(str(inc_c.datatype), str(out_c.datatype))\n",
    "    g[\"nodes\"] = ns\n",
    "    g[\"channels\"] = cs\n",
    "    add_dt_to_channels_g(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation functions\n",
    "\n",
    "# Compile Recursive CSDF graph\n",
    "\n",
    "def exploder(methods):\n",
    "    return lambda g: explode(g, methods)\n",
    "\n",
    "def explode(graph, methods):\n",
    "    for method in methods:\n",
    "        method(graph, exploder(methods))\n",
    "#         c\n",
    "    return graph\n",
    "\n",
    "\n",
    "def discrete_zip(graph, explode_method):\n",
    "#     add_dt_to_channels_g(graph)\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    def_len = 10\n",
    "    \n",
    "    # get Zip nodes\n",
    "    zipnodes = [n for n in nodes if getcn(n) == \"Zip\"]\n",
    "    # explode Zip nodes\n",
    "    for node in zipnodes:\n",
    "        name = node.name\n",
    "        \n",
    "        old_in_channels = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        assert(len(old_in_channels) >= 1)\n",
    "        assert(len(old_out_channel) <= 1)\n",
    "        \n",
    "        zippee = Zippee(node.name + \"XZippee\")\n",
    "        zippee.add_dt(Tuple(node.datatype.subdata.subdatals))\n",
    "        \n",
    "        \n",
    "        for din, i in zip(old_in_channels, range(len(old_in_channels))):\n",
    "            da_in = [x for x in node.input if x.name == din.dst_port][0]\n",
    "            da_out = Port(\"out\", name + \"XDA_out_x\"+str(i), [node.datatype.length])\n",
    "            da = Dearray(name + \"XDA_x\"+str(i), da_in, da_out)\n",
    "            da.datatype = din.datatype.subdata\n",
    "            din.dst_act = da.name\n",
    "            nodes.append(da)\n",
    "            channels.append(Channel(da.name, zippee.name, da_out.name, zippee.new_inport().name))\n",
    "            \n",
    "                          \n",
    "        ra_out = node.output\n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [node.datatype.length])\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Zip\")\n",
    "        ra.datatype = node.datatype\n",
    "        nodes += [ra, zippee]\n",
    "        old_out_channel[0].src_act = ra.name\n",
    "        channels.append(Channel(zippee.name, ra.name, zippee.output.name, ra.input.name))\n",
    "        \n",
    "        \n",
    "    # remove Zip nodes\n",
    "    nodes = [n for n in nodes if getcn(n) != \"Zip\"]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "\n",
    "\n",
    "def recursive_map(graph, explode_method):\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    def_len = 10\n",
    "    \n",
    "    # get Map nodes\n",
    "    mapnodes = [n for n in nodes if getcn(n) == \"Map\"]\n",
    "    # explode Map nodes\n",
    "    for node in mapnodes:\n",
    "#         print(node.name, getcn(node), node.datatype)\n",
    "        name = node.name\n",
    "        \n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        assert(len(old_in_channel) == 1)\n",
    "        assert(len(old_out_channel) <= 1)\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [node.rep])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        da.datatype = old_in_channel[0].datatype.subdata\n",
    "        ra_out = node.output\n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [node.rep])\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Map\")\n",
    "        ra.datatype = node.datatype\n",
    "        \n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        nodes += subgraph[\"nodes\"]\n",
    "        nodes += [da, ra]\n",
    "        \n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        channels += subgraph[\"channels\"]\n",
    "        so = subgraph[\"output\"].name\n",
    "        si = subgraph[\"inputs\"][0].name\n",
    "        channels += [Channel(da.name, \n",
    "                             get_node_by_port(subgraph[\"nodes\"], si).name, \n",
    "                             da_out.name, si), \n",
    "                     Channel(get_node_by_port(subgraph[\"nodes\"], so).name, \n",
    "                             ra.name, so, ra_in.name)]\n",
    "    # remove Map nodes\n",
    "    nodes = [n for n in nodes if getcn(n) != \"Map\"]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "\n",
    "def recursive_reduce(graph, explode_method):\n",
    "    def_len = 10\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    \n",
    "    # get Reduce nodes\n",
    "    reducenodes = [n for n in nodes if getcn(n).startswith(\"Reduce\")]\n",
    "    # explode Reduce nodes\n",
    "    for node in reducenodes:\n",
    "        name = node.name\n",
    "        # get channels\n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        \n",
    "        # make new nodes\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [node.rep])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        da.datatype = old_in_channel[0].datatype.subdata\n",
    "        \n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [1])\n",
    "        ra_out = node.output\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Reduce\")\n",
    "        ra.datatype = node.datatype\n",
    "        \n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        \n",
    "        # make param for recursion\n",
    "        para = Param(name + \"XPARA\", \"recursion\")\n",
    "        para.datatype = node.datatype.subdata\n",
    "        para.input.rate = [1] * node.rep\n",
    "        para_out_0 = para.new_outport([1] * node.rep)\n",
    "        para_out_1 = para.new_outport([0] * (node.rep - 1) + [1])\n",
    "        \n",
    "        # add nodes\n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        nodes += subgraph[\"nodes\"]\n",
    "        nodes += [da, ra, para]\n",
    "        \n",
    "        # add channels\n",
    "        si = subgraph[\"inputs\"]\n",
    "        so = subgraph[\"output\"].name\n",
    "        channels += [Channel(para.name, get_node_by_port(subgraph[\"nodes\"], si[1].name).name, \n",
    "                             para_out_0.name, si[1].name, 1),\n",
    "                     Channel(da.name, get_node_by_port(subgraph[\"nodes\"], si[0].name).name, \n",
    "                             da_out.name, si[0].name),\n",
    "                     Channel(get_node_by_port(subgraph[\"nodes\"], so).name, para.name,\n",
    "                             so, para.input.name),\n",
    "                     Channel(para.name, ra.name,\n",
    "                             para_out_1.name, ra_in.name)]\n",
    "        channels += subgraph[\"channels\"]\n",
    "        \n",
    "    # remove Reduce nodes\n",
    "    nodes = [n for n in nodes if not getcn(n).startswith(\"Reduce\")]\n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepcopy(g, i):\n",
    "    i = str(i)\n",
    "    newg = copy.deepcopy(g)\n",
    "    nodes = newg['nodes']\n",
    "    nodenames = [n.name for n in nodes]\n",
    "    for channel in newg['channels']:\n",
    "        if channel.src_act in nodenames and channel.dst_act in nodenames:\n",
    "            channel.name = channel.name + \"_x\" + i\n",
    "        if channel.src_act in nodenames:\n",
    "            channel.src_act = channel.src_act + \"_x\" + i\n",
    "            channel.src_port = channel.src_port + \"_x\" + i\n",
    "        if channel.dst_act in nodenames:\n",
    "            channel.dst_act = channel.dst_act + \"_x\" + i\n",
    "            channel.dst_port = channel.dst_port + \"_x\" + i\n",
    "    for node in nodes:\n",
    "        node.name = node.name + \"_x\" + i\n",
    "        for port in getports(node):\n",
    "            port.name = port.name + \"_x\" + i\n",
    "    return newg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_reducer(graph, explode_method, groupsize = 1):\n",
    "    def_len = 10\n",
    "    nodes = graph[\"nodes\"]\n",
    "    channels = graph[\"channels\"]\n",
    "    \n",
    "    # get Reduce nodes\n",
    "    reducenodes = [n for n in nodes if getcn(n) == (\"Reduce\")]\n",
    "    # explode Reduce nodes\n",
    "    for node in reducenodes:\n",
    "        name = node.name\n",
    "        # get channels\n",
    "        old_in_channel = [c for c in channels if c.dst_act == name]\n",
    "        old_out_channel = [c for c in channels if c.src_act == name]\n",
    "        inc_datatype = old_in_channel[0].datatype\n",
    "        \n",
    "        # make new nodes\n",
    "        da_in = node.input\n",
    "        da_out = Port(\"out\", name + \"XDA_out\", [node.rep])\n",
    "        da = Dearray(name + \"XDA\", da_in, da_out)\n",
    "        da.datatype = inc_datatype.subdata\n",
    "        \n",
    "        ra_in = Port(\"in\", name + \"XRA_in\", [1])\n",
    "        ra_out = node.output\n",
    "        ra = Rearray(name + \"XRA\", ra_in, ra_out, \"Reduce\")\n",
    "        ra.datatype = node.datatype\n",
    "        \n",
    "        if len(old_in_channel) == 1:\n",
    "            old_in_channel[0].dst_act = da.name\n",
    "        if len(old_out_channel) == 1:\n",
    "            old_out_channel[0].src_act = ra.name\n",
    "        \n",
    "        # make initial value\n",
    "        ival = Value(name + \"XInitVal\", node.initval, inc_datatype.subdata)\n",
    "        ival.add_dt(inc_datatype.subdata)\n",
    "        \n",
    "#         print(inc_datatype)\n",
    "        \n",
    "        # make Splitter and link to dearray\n",
    "        total_vals =  inc_datatype.length\n",
    "        routes = int(total_vals / groupsize)\n",
    "        remaining = total_vals % groupsize\n",
    "        \n",
    "        spl = Splitter(name+\"XSpl\", routes, groupsize, remaining)\n",
    "        spl.add_dt(inc_datatype.subdata)\n",
    "        channels += [Channel(da.name, spl.name, da_out.name, spl.input.name)]\n",
    "        \n",
    "        # add nodes\n",
    "        nodes += [da, ra, ival, spl]\n",
    "        subgraph = explode_method(node.subfunc)\n",
    "        datavals = [(spl.name, p.name) for p in spl.output] + [(ival.name, ival.output.name)]\n",
    "        count = 0\n",
    "        while len(datavals) > 1:\n",
    "            sg = deepcopy(subgraph, count)\n",
    "            count += 1\n",
    "            nodes += sg[\"nodes\"]\n",
    "            channels += sg[\"channels\"]\n",
    "            # add channels\n",
    "            in1 = datavals.pop(0)\n",
    "            in2 = datavals.pop(0)\n",
    "            si = sg[\"inputs\"]\n",
    "            \n",
    "            channels += [Channel(in1[0], get_node_by_port(sg[\"nodes\"], si[0].name).name, \n",
    "                                 in1[1], si[0].name),\n",
    "                         Channel(in2[0], get_node_by_port(sg[\"nodes\"], si[1].name).name, \n",
    "                                 in2[1], si[1].name)]\n",
    "            so = sg[\"output\"].name\n",
    "            datavals.append((get_node_by_port(sg[\"nodes\"], so).name, so))\n",
    "        in1 = datavals.pop()\n",
    "        channels.append(Channel(in1[0], ra.name, \n",
    "                                 in1[1], ra_in.name))\n",
    "        \n",
    "    # remove Reduce nodes\n",
    "    nodes = [n for n in nodes if not getcn(n)==\"Reduce\"]\n",
    "    \n",
    "    \n",
    "    graph[\"nodes\"] = nodes\n",
    "    graph[\"channels\"] = channels\n",
    "    return graph\n",
    "            \n",
    "\n",
    "\n",
    "parallel_reduce = lambda a, b: parallel_reducer(a, b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "recursive_explode = exploder([recursive_map, recursive_reduce])\n",
    "parallel_explode = exploder([parallel_reduce, recursive_map, recursive_reduce])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put together\n",
    "def fullfettle(filename, method, sizevar_file = None):\n",
    "    p = parse_file(filename, sizevar_file)\n",
    "    g = p['graph']\n",
    "    method(g)\n",
    "    add_dt_to_channels(p)\n",
    "    check_correct(g)\n",
    "    return p\n",
    "\n",
    "def smush_rede(p):\n",
    "    compose_maps(p['graph'])\n",
    "    add_dt_to_channels(p)\n",
    "    return p\n",
    "\n",
    "\n",
    "# Put together\n",
    "def get_rec_csdf(filename, sizevar_file = None):\n",
    "    return fullfettle(filename, recursive_explode, sizevar_file)\n",
    "def get_parallel_csdf(filename, sizevar_file = None):\n",
    "    return fullfettle(filename, parallel_explode, sizevar_file)\n",
    "\n",
    "def write_csdf_from_hl(from_file, to_file):\n",
    "    write_csdf(get_rec_csdf(from_file)[\"graph\"], to_file)\n",
    "\n",
    "def try_do(filename, methods, sizevar_file = None):\n",
    "    try:\n",
    "        p = parse_file(filename, sizevar_file)\n",
    "        g = p['graph']\n",
    "        exploder(methods)(g)\n",
    "        add_dt_to_channels(p)\n",
    "        check_correct(g)\n",
    "        return(p)\n",
    "    except Exception as e:\n",
    "        print(\"\\nCouldn't get CSDF for \" + filename)\n",
    "        raise(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     write_csdf_from_hl(add_cwd(\"highLevel/mmNN\"), add_cwd(\"csdf_xmls/mmNN\"))\n",
    "    \n",
    "def testr():\n",
    "    return get_rec_csdf(add_cwd(\"highLevel/mmNN\"))\n",
    "def testp():\n",
    "    return get_parallel_csdf(add_cwd(\"highLevel/mmNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "param node is  R n1\n",
      "param node is  I n2\n",
      "goodbye\n",
      "pushing ['n1', 'n2']\n",
      "Start: n1 Param\n",
      "Pushing: n1 Param\n",
      "n1 is pushing out node n6\n",
      "hello map n6\n",
      "n6  trigger  n5\n",
      "Hello\n",
      "param node is  v1 n3\n",
      "param node is  v2 n4\n",
      "goodbye\n",
      "pushing ['n3', 'n4']\n",
      "Start: n3 Param\n",
      "Pushing: n3 Param\n",
      "n3 is pushing out node n5\n",
      "isn't zip\n",
      "Start: n5 Mather\n",
      "Start: n6 Reduce\n",
      "Pushing: n6 Reduce\n",
      "n6 is pushing out node n15\n",
      "hello map n15\n",
      "n15  trigger  n13\n",
      "Hello\n",
      "param node is  A n7\n",
      "param node is  B n8\n",
      "goodbye\n",
      "pushing ['n7', 'n8']\n",
      "Start: n7 Param\n",
      "Pushing: n7 Param\n",
      "n7 is pushing out node n14\n",
      "is zip\n",
      "Start: n14 Zip\n",
      "Pushing: n14 Zip\n",
      "n14 is pushing out node n13\n",
      "hello map n13\n",
      "n13  trigger  n10\n",
      "Hello\n",
      "param node is  x n9\n",
      "goodbye\n",
      "pushing ['n9']\n",
      "Start: n9 Param\n",
      "Pushing: n9 Param\n",
      "n9 is pushing out node n11\n",
      "isn't zip\n",
      "Start: n11 Get\n",
      "Pushing: n11 Get\n",
      "n11 is pushing out node n10\n",
      "not all inputs\n",
      "n9 is pushing out node n12\n",
      "isn't zip\n",
      "Start: n12 Get\n",
      "Pushing: n12 Get\n",
      "n12 is pushing out node n10\n",
      "isn't zip\n",
      "Start: n10 Mather\n",
      "Start: n13 Map\n",
      "Start: n15 Reduce\n",
      "Start: n8 Param\n",
      "Pushing: n8 Param\n",
      "n8 is pushing out node n14\n",
      "is zip\n",
      "Start: n14 Zip\n",
      "Start: n4 Param\n",
      "Pushing: n4 Param\n",
      "n4 is pushing out node n5\n",
      "isn't zip\n",
      "Start: n5 Mather\n",
      "Start: n6 Reduce\n",
      "Start: n2 Param\n",
      "Pushing: n2 Param\n",
      "n13 Map Array (10, Float)\n"
     ]
    }
   ],
   "source": [
    "k = get_rec_csdf(add_cwd(\"highLevel/mydot\"), [10,10,10,10,10])\n",
    "zz = k['graph']['nodes'][10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array (10, Tuple (Float, Float))\n"
     ]
    }
   ],
   "source": [
    "print(zz.datatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sfile.txt', 'w') as f:\n",
    "    f.write('\\n'.join(['10']*5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = testr()['graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': [<__main__.Param at 0x10828d410>,\n",
       "  <__main__.Param at 0x10828d450>,\n",
       "  <__main__.Param at 0x10828d6d0>,\n",
       "  <__main__.Transpose at 0x1081a9850>,\n",
       "  <__main__.Param at 0x10828dc10>,\n",
       "  <__main__.Zip at 0x1081a9fd0>,\n",
       "  <__main__.Param at 0x1081a48d0>,\n",
       "  <__main__.Get at 0x1081a45d0>,\n",
       "  <__main__.Get at 0x1081a4310>,\n",
       "  <__main__.Mather at 0x1081a4750>,\n",
       "  <__main__.Dearray at 0x107e5d990>,\n",
       "  <__main__.Rearray at 0x107e5d410>,\n",
       "  <__main__.Mather at 0x10828dd10>,\n",
       "  <__main__.Param at 0x10828ded0>,\n",
       "  <__main__.Param at 0x10828dfd0>,\n",
       "  <__main__.Dearray at 0x1081ac490>,\n",
       "  <__main__.Rearray at 0x1080478d0>,\n",
       "  <__main__.Param at 0x1080470d0>,\n",
       "  <__main__.Dearray at 0x108177710>,\n",
       "  <__main__.Rearray at 0x1081778d0>,\n",
       "  <__main__.Dearray at 0x10819dc90>,\n",
       "  <__main__.Rearray at 0x108177d10>],\n",
       " 'channels': [<__main__.Channel at 0x10819d550>,\n",
       "  <__main__.Channel at 0x1081a9150>,\n",
       "  <__main__.Channel at 0x1081a9290>,\n",
       "  <__main__.Channel at 0x1081a9b10>,\n",
       "  <__main__.Channel at 0x1081a9890>,\n",
       "  <__main__.Channel at 0x1081a9750>,\n",
       "  <__main__.Channel at 0x1081a98d0>,\n",
       "  <__main__.Channel at 0x1081a4290>,\n",
       "  <__main__.Channel at 0x1081a96d0>,\n",
       "  <__main__.Channel at 0x1081a9490>,\n",
       "  <__main__.Channel at 0x1081a9e90>,\n",
       "  <__main__.Channel at 0x10828db10>,\n",
       "  <__main__.Channel at 0x1081a9810>,\n",
       "  <__main__.Channel at 0x107e42a10>,\n",
       "  <__main__.Channel at 0x107e42f90>,\n",
       "  <__main__.Channel at 0x107e42e10>,\n",
       "  <__main__.Channel at 0x107e423d0>,\n",
       "  <__main__.Channel at 0x10827f1d0>,\n",
       "  <__main__.Channel at 0x10827f490>,\n",
       "  <__main__.Channel at 0x1081a9110>,\n",
       "  <__main__.Channel at 0x108042e50>,\n",
       "  <__main__.Channel at 0x10819d510>,\n",
       "  <__main__.Channel at 0x108177f50>],\n",
       " 'inputs': [<__main__.Port at 0x10828d550>, <__main__.Port at 0x10828d510>],\n",
       " 'output': <__main__.Port at 0x1081a9190>}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
